{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/clean-blog/source/css/article.styl","path":"css/article.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/base.styl","path":"css/base.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/mixins.styl","path":"css/mixins.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/variables.styl","path":"css/variables.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/img/about-bg.jpg","path":"img/about-bg.jpg","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/img/home-bg.jpg","path":"img/home-bg.jpg","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/img/contact-bg.jpg","path":"img/contact-bg.jpg","modified":0,"renderable":1},{"_id":"source/images/home-bg2.png","path":"images/home-bg2.png","modified":0,"renderable":0},{"_id":"source/images/brainvault_small.png","path":"images/brainvault_small.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"b8e5951c497e1060bfccf7be197be3bad8cb1885","modified":1468521558000},{"_id":"themes/clean-blog/LICENSE","hash":"8726b416df4f067cff579e859f05c4b594b8be09","modified":1468437702000},{"_id":"themes/clean-blog/README.md","hash":"c5c7b0fd01aa229304e7b00697517aaca51de577","modified":1468437702000},{"_id":"themes/clean-blog/_config.yml","hash":"091f253f4e7df9f7f3d2030d970545aadc93e689","modified":1468444912000},{"_id":"source/_posts/Docker-Hacks.md","hash":"126bb22d4ad07f6e78b7525364864215ef7772dc","modified":1470172256000},{"_id":"source/_posts/BASH-tricks.md","hash":"9234bb6e6089393474d70228359e91d56ada1ae2","modified":1470172767000},{"_id":"source/_posts/Infiniband-performance-tuning.md","hash":"2794d92979f1fdf8f2a6d8b1bc3a75b54106b6f7","modified":1470174355000},{"_id":"source/_posts/Serverless-Docker.md","hash":"bf1d4745a68bd38cda8a0d6a06af908bf1da6f72","modified":1470172280000},{"_id":"source/_posts/Tricks-for-finding-directory-space-usage.md","hash":"37578058080b046f6d9fff1ab5d250df7300922c","modified":1470173116000},{"_id":"source/_posts/Using-Ansible-to-communicate-with-rest-API.md","hash":"09470b93078948dfe4b71d13a672977d89eb662c","modified":1470172758000},{"_id":"source/_posts/apt-cacher-ng-with-docker-builds.md","hash":"626c12dcb2d63403aaec441aab3da075d525333a","modified":1470172243000},{"_id":"source/_posts/smp-affinity-makes-a-difference.md","hash":"78dc622adc6fa9daaf45431cb766c3b6304c2dab","modified":1470173241000},{"_id":"themes/clean-blog/languages/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1468437702000},{"_id":"themes/clean-blog/languages/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1468437702000},{"_id":"themes/clean-blog/languages/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1468437702000},{"_id":"themes/clean-blog/languages/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1468437702000},{"_id":"themes/clean-blog/languages/fr.yml","hash":"e9e6f7cb362ebb7997f11027498a2748fe3bac95","modified":1468437702000},{"_id":"themes/clean-blog/languages/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1468437702000},{"_id":"themes/clean-blog/languages/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1468437702000},{"_id":"themes/clean-blog/languages/pt.yml","hash":"1d0c3689eb32fe13f37f8f6f303af7624ebfbaf0","modified":1468437702000},{"_id":"themes/clean-blog/languages/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1468437702000},{"_id":"themes/clean-blog/languages/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1468437702000},{"_id":"themes/clean-blog/languages/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1468437702000},{"_id":"themes/clean-blog/layout/archive.ejs","hash":"ad0da72df13ce3566985bb390c2c9a9352cf4f07","modified":1468437702000},{"_id":"themes/clean-blog/layout/index.ejs","hash":"237bbf8c4db6f11cf4fdc82c421f5e0ab7c61b85","modified":1468521117000},{"_id":"themes/clean-blog/layout/layout.ejs","hash":"3a244ef80c58591dda5cfd3aae6654a74f9abdc7","modified":1468437702000},{"_id":"themes/clean-blog/layout/page.ejs","hash":"38382e9bbeb6b8d2eafbd53fff2984111f524c1a","modified":1468437702000},{"_id":"themes/clean-blog/layout/post.ejs","hash":"38382e9bbeb6b8d2eafbd53fff2984111f524c1a","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/after-footer.ejs","hash":"80970a6cfbf9b1abe0c472636b321a9be08fdc43","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/article-archive.ejs","hash":"3d8d98c6545b8332a6d6ed4f8b00327df03ea945","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/article-categories.ejs","hash":"5a0bf5a20f670621d8013c9b9d7976b45c8aa80f","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/article-full.ejs","hash":"8d63ce240bbcc850b5d438d1f45ad9441ac1c9cc","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/article-index.ejs","hash":"e433df4e245e2d4c628052c6e59966563542d94d","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/article-tags.ejs","hash":"6136434be09056c1466149cecb3cc2e80d107999","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/comments.ejs","hash":"3fedb75436439d1d6979b7e4d20d48a593e12be4","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/footer.ejs","hash":"412226245d15a9caffa4fc719d2112756fb72e02","modified":1468606070000},{"_id":"themes/clean-blog/layout/_partial/gallery.ejs","hash":"21e4f28909f4a79ff7d9f10bdfef6a8cb11632bf","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/google-analytics.ejs","hash":"4e6e8de9becea5a1636a4dcadcf7a10c06e2426e","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/head.ejs","hash":"093616c5338b3e51ba52e79d0271d96afb98e575","modified":1468437702000},{"_id":"themes/clean-blog/layout/_partial/menu.ejs","hash":"65251285b76141504130081fad36834fe15e46d6","modified":1468521654000},{"_id":"themes/clean-blog/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1468437702000},{"_id":"themes/clean-blog/source/css/article.styl","hash":"f5294d7a3d6127fcb287de3ff0c12aebb1766c7b","modified":1468437702000},{"_id":"themes/clean-blog/source/css/base.styl","hash":"f0a6fcf58fe515e1359acde0ed34081f580ec7a3","modified":1468437702000},{"_id":"themes/clean-blog/source/css/mixins.styl","hash":"892f55e8a71f2e23a52e48e217dad3303bbad913","modified":1468437702000},{"_id":"themes/clean-blog/source/css/style.styl","hash":"c40dc495a41007d21c59f342ee42b2d31d7b5ff4","modified":1468437702000},{"_id":"themes/clean-blog/source/css/variables.styl","hash":"cd82df5ca8dfbcfec12d833f01adfac00878e835","modified":1468437702000},{"_id":"themes/clean-blog/source/img/about-bg.jpg","hash":"d39126a6456f2bac0169d1779304725f179c9900","modified":1468437702000},{"_id":"themes/clean-blog/source/img/home-bg.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1468437702000},{"_id":"themes/clean-blog/source/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1468437702000},{"_id":"source/images/home-bg2.png","hash":"97e52dcc68628fe0e7b3396fe248de53931d0978","modified":1470180497000},{"_id":"public/2016/08/02/BASH-tricks/index.html","hash":"a49f1227574fa227dc549c0dd3cc151215a0fda2","modified":1470176835750},{"_id":"public/2016/07/24/Serverless-Docker/index.html","hash":"47286fdb9ab60b906aa193dbb1cae1605c932f4b","modified":1470176835751},{"_id":"public/2016/07/20/apt-cacher-ng-with-docker-builds/index.html","hash":"d1e961695f2fdbf76b0a64a0afa9a554641ed4b8","modified":1470176835751},{"_id":"public/2016/07/18/Docker-Hacks/index.html","hash":"cd77a97a6d73b284be72958868c7db910d39984f","modified":1470176835751},{"_id":"public/2016/07/15/Using-Ansible-to-communicate-with-rest-API/index.html","hash":"295a207f2e54540ccb128b51e7afc2bbc423d03c","modified":1470176835751},{"_id":"public/2016/07/14/Tricks-for-finding-directory-space-usage/index.html","hash":"bd18d13fa91371cc8368380b58df64e6cbc66702","modified":1470176835751},{"_id":"public/2016/07/13/smp-affinity-makes-a-difference/index.html","hash":"b959ed6a8db0470c7cccdcd096d0fecf3addd7b7","modified":1470176835751},{"_id":"public/archives/index.html","hash":"edec3e4c9e76067b267c0636203f3360ace1e7ae","modified":1470176835751},{"_id":"public/archives/2016/07/index.html","hash":"7c2ed1f3d6e88e3b7a961494a2e5b690dc3cbd90","modified":1470176835751},{"_id":"public/archives/2016/index.html","hash":"19fad6b9b32fc61996133496ef80002c20517cce","modified":1470176835751},{"_id":"public/archives/2016/08/index.html","hash":"514555f004587286c3b523d81c60cd24f7b75a95","modified":1470176835752},{"_id":"public/index.html","hash":"5054e9320728933022fc1346931f28ae3901a2bc","modified":1470176835752},{"_id":"public/tags/docker/index.html","hash":"b176d8ee9d0f1e150589754d35c1b9215325905e","modified":1470176835752},{"_id":"public/tags/hacks/index.html","hash":"2c18dd7af3abf496f4b827ecbf28106f967183c8","modified":1470176835752},{"_id":"public/tags/golang/index.html","hash":"2c1478d3527225ec3a30522094d3c4af3e0624fc","modified":1470176835752},{"_id":"public/tags/go-dockerclient/index.html","hash":"fa9d09326a864e340606519bbe7e43408565bb9d","modified":1470176835752},{"_id":"public/tags/go-dexec/index.html","hash":"3ece47b5ffe18fe96e6879491cef3b302a38f6b2","modified":1470176835752},{"_id":"public/tags/DOCKER/index.html","hash":"387284bc73bd14edd7c6eb1c1dd59485792a99dd","modified":1470176835752},{"_id":"public/tags/DOCKERFILE/index.html","hash":"2e16b75944a50193ebbb92b516310345f1188228","modified":1470176835752},{"_id":"public/tags/APT-CACHER-NG/index.html","hash":"82d97aa5054e4c4d8cae56a8260e461eda8f6e79","modified":1470176835752},{"_id":"public/tags/APT-GET/index.html","hash":"b69839282fc4ebf741d296da6e9c56bd9eed67ed","modified":1470176835752},{"_id":"public/tags/UBUNTU/index.html","hash":"13941fc8c49a15afd4ea56c443a47b1391e7e54e","modified":1470176835752},{"_id":"public/tags/CONFIGURATION/index.html","hash":"b43b845423070ce30e3ba32eabc042be9849cecb","modified":1470176835752},{"_id":"public/tags/DOCKER-FOR-MAC/index.html","hash":"9443bbab9329462874a49bc7b3455152d9da37ac","modified":1470176835752},{"_id":"public/2016/07/13/Infiniband-performance-tuning/index.html","hash":"7a05aa138bbb18d92393894e8d5abf9e0cd56d8e","modified":1470176835752},{"_id":"public/img/about-bg.jpg","hash":"d39126a6456f2bac0169d1779304725f179c9900","modified":1470176835756},{"_id":"public/css/article.css","hash":"f0ee490e1207191946fffc9444f891e9b7ae7289","modified":1470176836141},{"_id":"public/css/base.css","hash":"5bdbdf83ad61e80c537bd75b5442c8b0aac1e0f6","modified":1470176836141},{"_id":"public/css/mixins.css","hash":"45146e7f4346351cd7f364de344aecf9574475f9","modified":1470176836141},{"_id":"public/css/style.css","hash":"4549fbe615459f12cc2e4f560036f911cd51b121","modified":1470176836141},{"_id":"public/css/variables.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1470176836141},{"_id":"public/img/home-bg.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1470176836142},{"_id":"public/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1470176836146},{"_id":"public/images/home-bg2.png","hash":"97e52dcc68628fe0e7b3396fe248de53931d0978","modified":1470180502893},{"_id":"source/images/brainvault_small.png","hash":"17baea50231ad66c50d867b4479271c59d78ae23","modified":1470180497000},{"_id":"public/images/brainvault_small.png","hash":"17baea50231ad66c50d867b4479271c59d78ae23","modified":1470180502889}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"Docker Hacks","date":"2016-07-18T21:09:25.000Z","_content":"\nI've found this snippet handy when you need to restart the docker daemon and want to resume currently running containers.\n\n\n``` bash\ndocker ps |tail -n +2 > /docker.running\ncat /docker.running\nservice docker restart\ndocker start $(awk '{print $1}' /docker.running)\n```\n\n","source":"_posts/Docker-Hacks.md","raw":"---\ntitle: Docker Hacks\ndate: 2016-07-18 14:09:25\ntags:\n    - docker\n    - hacks\n---\n\nI've found this snippet handy when you need to restart the docker daemon and want to resume currently running containers.\n\n\n``` bash\ndocker ps |tail -n +2 > /docker.running\ncat /docker.running\nservice docker restart\ndocker start $(awk '{print $1}' /docker.running)\n```\n\n","slug":"Docker-Hacks","published":1,"updated":"2016-08-02T21:10:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1bud30000hrtfjb4ftshd","content":"<p>I’ve found this snippet handy when you need to restart the docker daemon and want to resume currently running containers.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker ps |tail -n +2 &gt; /docker.running</div><div class=\"line\">cat /docker.running</div><div class=\"line\">service docker restart</div><div class=\"line\">docker start $(awk <span class=\"string\">'&#123;print $1&#125;'</span> /docker.running)</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>I’ve found this snippet handy when you need to restart the docker daemon and want to resume currently running containers.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker ps |tail -n +2 &gt; /docker.running</div><div class=\"line\">cat /docker.running</div><div class=\"line\">service docker restart</div><div class=\"line\">docker start $(awk <span class=\"string\">'&#123;print $1&#125;'</span> /docker.running)</div></pre></td></tr></table></figure>\n"},{"title":"Infiniband performance tuning","date":"2016-07-13T21:27:51.000Z","_content":"\nI don’t currently have access to the original hardware I used so most of this is off memory and some notes I made.\nAlso I’ll present the caveat and warning that all these things I tested not with a view to stability for a production environment but this allowed me to get an Idea of what things I could do to eke out more performance.\n\nThere were a few of basic designs I tested with. The hardware was a supermicro chassis with E5 series intel cpu’s 2x quad core 64GB ram. The raid card was LSI 9266-8i (capacitor bbu + fastpath and cachecade addons) that connected to a supermicro sas expander backplane. I tested with several different array’s of disks the most interesting were the SSD’s so for this example I was using 10 samsung 840pro 512gb ssd’s in raid 10 plus 2 hotspares. This server setup was designed to serve raw LVM based lun’s to single U nodes via 20gb Infiniband running ISCSI protocol.\n\nHere is a general list of stuff I did to maximize the performance I learned a lot about what things made the most differences. I also worked extensively with the engineers at LSI to optimize things.\n\n## Hardware.\n\n## PCI slots.\n\nIts not stated anywhere in the documentation but faster is not always better. Working directly with the LSI engineers I learned that for the greatest speed and stability you should be using an 8x pci slot for the raid card. Also you want to make sure that your infiniband cards are registering at the right speeds on the PCI bus. You’ll want to use ‘lspci’ with lots of verbosity to verify that the pci cards come up at the right speeds. I had some driver and BIOS issues that caused some infiniband cards to only come up at half speed or 2.5gb/s vs 5.0gb/s\n\n## BIOS updates\n\nFor the head nodes I was using INTEL chassis with Intel chipsets. These were very buggy and needed to be constantly updated as Intel was fixing things in the BIOS which caused great instability. Make sure all the BIOS is latest and greatest. Supermicro’s firmware’s seemed much more stable in comparison.\n\n## Protocols.\n\nThis is a very interesting topic. In a nutshell this was probably the biggest benefit. Originally I had been using Ethernet over infiniband or IPoIB which gave me very fast speeds compared to 1gb networking but no where near the speeds I would expect to see from a raid10 SSD array via 20gb infiniband. Using IPoIB also bogged down cpu’s so wasn’t ideal in my situation. So the magic really starts when you use iscsi + iser + RDMA.\n\nYou still need IP based communication to do the target discovery but once the nodes all know about each other they switch to using RDMA which is way more efficient. This requires using a iscsi target software that supports iser as well as compiling the drivers for your current kernel from the Mellanox or OFED package of your choice.\n\n## Linux Distribution\n\nPrimarily I tested centos 6 however I also tested with Ubuntu 12.04. The best performance really depended on the kernel version.\n\n## Kernel\n\nI tested with centos 6 default and Ubuntu’s 12.04 kernels and they both gave mediocre results. I highly recommend the mainline kernel repo the mainline kernel had some significant performance patches/fixes for SSD’s in general.\n\n[elrepo Mainline Kernel](http://elrepo.org/tiki/kernel-ml)\n\n## ISCSI software\n\nIn Linux there are a few choices here. Originally I had been using ietd but then moved to tgtd because of support for iser RDMA which was a critical performance gain.\n\n[stgt](http://stgt.sourceforge.net/)\n\n## Infiniband software/drivers.\n\nOriginally I had worked with the OFED drivers but soon realized that my Mellanox branded cards performed better when I used the firmware specifically from Mellanox it was an older revision of OFED but compiled specifically for my cards.\n\n[MLNX branded drivers](http://www.mellanox.com/page/products_dyn?product_family=26&mtag=linux_sw_drivers)\n\n\nThis was a very helpful guide on the tuning recommendations I followed.\n[Performance Tuning Guide for Mellanox Network Adapters](http://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters.pdf)\n\n\n## sysctl.conf\n\nThe settings in sysctl.conf made significant improvements on performance.\n\n## Network settings\n\n``` bash\n\nnet.ipv4.tcp_timestamps=0\nnet.ipv4.tcp_sack=0\nnet.ipv4.tcp_mem=16777216 16777216 16777216\nnet.ipv4.tcp_rmem=4096 87380 16777216\nnet.ipv4.tcp_wmem=4096 65536 16777216\nnet.ipv4.tcp_low_latency = 1\nnet.core.rmem_max=16777216\nnet.core.wmem_max=16777216\nnet.core.rmem_default=16777216\nnet.core.wmem_default=16777216\nnet.core.optmem_max=16777216\nnet.core.netdev_max_backlog=250000\n```\n\n\n## Virtual memory settings\n\nOf the sysctl settings these defintily make a huge difference. Depending on the workloads of the guest machines these settings could be tweaked per your environment. I noticed significant differences in performance based on different types of workloads. YMMV\n\n``` bash\nvm.swappiness=0\nvm.zone_reclaim_mode=0\nvm.dirty_ratio=10\nvm.dirty_background_ratio=5\n```\n\n\n## IRQ affinity\n\nThis was a HUGE item to improve performance. First disable irqbalance and manually pin your cpu/irq affinity.\nThe Mellanox package comes with a shell script that was helpful in resetting the affinity. I used this same script to help balance between my raid card and Infiniband card. Also since I had dual a dual socket motherboard I thought it best to install the infiniband card on one PCI bus and the raid card on the other bus with the other cpu.\nset_irq_affinity_cpulist.sh is the name of the script.\n\n### Unbalanced\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n```\n\n### Balanced\n\n``` bash\n$ cat /proc/interrupts |grep mega\n  80:     650586          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:     242572      87388          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:     240192          0     247210          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:      41286          0          0      42410          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:     184197          0          0          0      52479          0          0          0  IR-PCI-MSI-edge      megasas\n  85:     113659          0          0          0          0      58953          0          0  IR-PCI-MSI-edge      megasas\n  86:      33822          0          0          0          0          0      37659          0  IR-PCI-MSI-edge      megasas\n  87:      28633          0          0          0          0          0          0      35605  IR-PCI-MSI-edge      megasas\n```\n\n\nSome additional reading on interrupts spreading.\n\n[msi-x-the-right-way-to-spread-interrupt-load](http://www.alexonlinux.com/msi-x-the-right-way-to-spread-interrupt-load)\n\n[smp-affinity-and-proper-interrupt-handling-in-linux](http://www.alexonlinux.com/smp-affinity-and-proper-interrupt-handling-in-linux)\n\n\n- Openib.conf\n\n    This file allowed me to enable and disable certain drivers. Specifically I wanted to enable the iser as well as IPoIB\n\n- CPU frequency/speed.\n\n- Raid firmware\n\n    If you update the raid firmware make sure that all the settings are set correctly still.\n\n    Also double check to make sure that the drivers are using enough interuppts.\n    For example the stock megaraid_sas driver was only using 1 interrupt. Installing the latest driver from LSI allowed all 8 to be used.\n\n### Before and then after installing the new driver.\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n```\n\nCheck this link at the bottom it has an attached PDF which is a really good runthrough of all the information you need.\n\n[LSI tuning guide](http://mycusthelp.info/LSI/_cs/AnswerDetail.aspx?inc=8196)\n\n\n## C-states\n\n## Disk Schedulers\n\n## Hugepages\n\n## SSD brands\n\nThe samsung 840pro’s gave much much worse performance than earlier plextor m5 256gb drives I used in the past. These newer samsung drives are much slower and have a known issue with the caching on disk that conflicts with LSI firmware making them good or desktop machines but not very good in a Raid Array. I highly recommend researching this issue. Some people have worked around this by flashing differently branded firmwares onto the LSI branded cards. I wasn’t brave enough to risk bricking my raid cards so I didn’t try it.\n\n\n## Mount options\n\nMuch performance can be gained as well by adding less safe mount options.\nThe best performance I saw was when I tested against ext4 with\n\n``` bash\ndiscard,noatime,data=writeback,barrier=0,acl,user_xattr,nobh\n```\n\nMore to come...\n\n\n","source":"_posts/Infiniband-performance-tuning.md","raw":"---\ntitle: Infiniband performance tuning\ndate: 2016-07-13 14:27:51\ntags:\n---\n\nI don’t currently have access to the original hardware I used so most of this is off memory and some notes I made.\nAlso I’ll present the caveat and warning that all these things I tested not with a view to stability for a production environment but this allowed me to get an Idea of what things I could do to eke out more performance.\n\nThere were a few of basic designs I tested with. The hardware was a supermicro chassis with E5 series intel cpu’s 2x quad core 64GB ram. The raid card was LSI 9266-8i (capacitor bbu + fastpath and cachecade addons) that connected to a supermicro sas expander backplane. I tested with several different array’s of disks the most interesting were the SSD’s so for this example I was using 10 samsung 840pro 512gb ssd’s in raid 10 plus 2 hotspares. This server setup was designed to serve raw LVM based lun’s to single U nodes via 20gb Infiniband running ISCSI protocol.\n\nHere is a general list of stuff I did to maximize the performance I learned a lot about what things made the most differences. I also worked extensively with the engineers at LSI to optimize things.\n\n## Hardware.\n\n## PCI slots.\n\nIts not stated anywhere in the documentation but faster is not always better. Working directly with the LSI engineers I learned that for the greatest speed and stability you should be using an 8x pci slot for the raid card. Also you want to make sure that your infiniband cards are registering at the right speeds on the PCI bus. You’ll want to use ‘lspci’ with lots of verbosity to verify that the pci cards come up at the right speeds. I had some driver and BIOS issues that caused some infiniband cards to only come up at half speed or 2.5gb/s vs 5.0gb/s\n\n## BIOS updates\n\nFor the head nodes I was using INTEL chassis with Intel chipsets. These were very buggy and needed to be constantly updated as Intel was fixing things in the BIOS which caused great instability. Make sure all the BIOS is latest and greatest. Supermicro’s firmware’s seemed much more stable in comparison.\n\n## Protocols.\n\nThis is a very interesting topic. In a nutshell this was probably the biggest benefit. Originally I had been using Ethernet over infiniband or IPoIB which gave me very fast speeds compared to 1gb networking but no where near the speeds I would expect to see from a raid10 SSD array via 20gb infiniband. Using IPoIB also bogged down cpu’s so wasn’t ideal in my situation. So the magic really starts when you use iscsi + iser + RDMA.\n\nYou still need IP based communication to do the target discovery but once the nodes all know about each other they switch to using RDMA which is way more efficient. This requires using a iscsi target software that supports iser as well as compiling the drivers for your current kernel from the Mellanox or OFED package of your choice.\n\n## Linux Distribution\n\nPrimarily I tested centos 6 however I also tested with Ubuntu 12.04. The best performance really depended on the kernel version.\n\n## Kernel\n\nI tested with centos 6 default and Ubuntu’s 12.04 kernels and they both gave mediocre results. I highly recommend the mainline kernel repo the mainline kernel had some significant performance patches/fixes for SSD’s in general.\n\n[elrepo Mainline Kernel](http://elrepo.org/tiki/kernel-ml)\n\n## ISCSI software\n\nIn Linux there are a few choices here. Originally I had been using ietd but then moved to tgtd because of support for iser RDMA which was a critical performance gain.\n\n[stgt](http://stgt.sourceforge.net/)\n\n## Infiniband software/drivers.\n\nOriginally I had worked with the OFED drivers but soon realized that my Mellanox branded cards performed better when I used the firmware specifically from Mellanox it was an older revision of OFED but compiled specifically for my cards.\n\n[MLNX branded drivers](http://www.mellanox.com/page/products_dyn?product_family=26&mtag=linux_sw_drivers)\n\n\nThis was a very helpful guide on the tuning recommendations I followed.\n[Performance Tuning Guide for Mellanox Network Adapters](http://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters.pdf)\n\n\n## sysctl.conf\n\nThe settings in sysctl.conf made significant improvements on performance.\n\n## Network settings\n\n``` bash\n\nnet.ipv4.tcp_timestamps=0\nnet.ipv4.tcp_sack=0\nnet.ipv4.tcp_mem=16777216 16777216 16777216\nnet.ipv4.tcp_rmem=4096 87380 16777216\nnet.ipv4.tcp_wmem=4096 65536 16777216\nnet.ipv4.tcp_low_latency = 1\nnet.core.rmem_max=16777216\nnet.core.wmem_max=16777216\nnet.core.rmem_default=16777216\nnet.core.wmem_default=16777216\nnet.core.optmem_max=16777216\nnet.core.netdev_max_backlog=250000\n```\n\n\n## Virtual memory settings\n\nOf the sysctl settings these defintily make a huge difference. Depending on the workloads of the guest machines these settings could be tweaked per your environment. I noticed significant differences in performance based on different types of workloads. YMMV\n\n``` bash\nvm.swappiness=0\nvm.zone_reclaim_mode=0\nvm.dirty_ratio=10\nvm.dirty_background_ratio=5\n```\n\n\n## IRQ affinity\n\nThis was a HUGE item to improve performance. First disable irqbalance and manually pin your cpu/irq affinity.\nThe Mellanox package comes with a shell script that was helpful in resetting the affinity. I used this same script to help balance between my raid card and Infiniband card. Also since I had dual a dual socket motherboard I thought it best to install the infiniband card on one PCI bus and the raid card on the other bus with the other cpu.\nset_irq_affinity_cpulist.sh is the name of the script.\n\n### Unbalanced\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n```\n\n### Balanced\n\n``` bash\n$ cat /proc/interrupts |grep mega\n  80:     650586          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:     242572      87388          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:     240192          0     247210          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:      41286          0          0      42410          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:     184197          0          0          0      52479          0          0          0  IR-PCI-MSI-edge      megasas\n  85:     113659          0          0          0          0      58953          0          0  IR-PCI-MSI-edge      megasas\n  86:      33822          0          0          0          0          0      37659          0  IR-PCI-MSI-edge      megasas\n  87:      28633          0          0          0          0          0          0      35605  IR-PCI-MSI-edge      megasas\n```\n\n\nSome additional reading on interrupts spreading.\n\n[msi-x-the-right-way-to-spread-interrupt-load](http://www.alexonlinux.com/msi-x-the-right-way-to-spread-interrupt-load)\n\n[smp-affinity-and-proper-interrupt-handling-in-linux](http://www.alexonlinux.com/smp-affinity-and-proper-interrupt-handling-in-linux)\n\n\n- Openib.conf\n\n    This file allowed me to enable and disable certain drivers. Specifically I wanted to enable the iser as well as IPoIB\n\n- CPU frequency/speed.\n\n- Raid firmware\n\n    If you update the raid firmware make sure that all the settings are set correctly still.\n\n    Also double check to make sure that the drivers are using enough interuppts.\n    For example the stock megaraid_sas driver was only using 1 interrupt. Installing the latest driver from LSI allowed all 8 to be used.\n\n### Before and then after installing the new driver.\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n```\n\nCheck this link at the bottom it has an attached PDF which is a really good runthrough of all the information you need.\n\n[LSI tuning guide](http://mycusthelp.info/LSI/_cs/AnswerDetail.aspx?inc=8196)\n\n\n## C-states\n\n## Disk Schedulers\n\n## Hugepages\n\n## SSD brands\n\nThe samsung 840pro’s gave much much worse performance than earlier plextor m5 256gb drives I used in the past. These newer samsung drives are much slower and have a known issue with the caching on disk that conflicts with LSI firmware making them good or desktop machines but not very good in a Raid Array. I highly recommend researching this issue. Some people have worked around this by flashing differently branded firmwares onto the LSI branded cards. I wasn’t brave enough to risk bricking my raid cards so I didn’t try it.\n\n\n## Mount options\n\nMuch performance can be gained as well by adding less safe mount options.\nThe best performance I saw was when I tested against ext4 with\n\n``` bash\ndiscard,noatime,data=writeback,barrier=0,acl,user_xattr,nobh\n```\n\nMore to come...\n\n\n","slug":"Infiniband-performance-tuning","published":1,"updated":"2016-08-02T21:45:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1bud80001hrtflq6ejtjr","content":"<p>I don’t currently have access to the original hardware I used so most of this is off memory and some notes I made.<br>Also I’ll present the caveat and warning that all these things I tested not with a view to stability for a production environment but this allowed me to get an Idea of what things I could do to eke out more performance.</p>\n<p>There were a few of basic designs I tested with. The hardware was a supermicro chassis with E5 series intel cpu’s 2x quad core 64GB ram. The raid card was LSI 9266-8i (capacitor bbu + fastpath and cachecade addons) that connected to a supermicro sas expander backplane. I tested with several different array’s of disks the most interesting were the SSD’s so for this example I was using 10 samsung 840pro 512gb ssd’s in raid 10 plus 2 hotspares. This server setup was designed to serve raw LVM based lun’s to single U nodes via 20gb Infiniband running ISCSI protocol.</p>\n<p>Here is a general list of stuff I did to maximize the performance I learned a lot about what things made the most differences. I also worked extensively with the engineers at LSI to optimize things.</p>\n<h2 id=\"Hardware\"><a href=\"#Hardware\" class=\"headerlink\" title=\"Hardware.\"></a>Hardware.</h2><h2 id=\"PCI-slots\"><a href=\"#PCI-slots\" class=\"headerlink\" title=\"PCI slots.\"></a>PCI slots.</h2><p>Its not stated anywhere in the documentation but faster is not always better. Working directly with the LSI engineers I learned that for the greatest speed and stability you should be using an 8x pci slot for the raid card. Also you want to make sure that your infiniband cards are registering at the right speeds on the PCI bus. You’ll want to use ‘lspci’ with lots of verbosity to verify that the pci cards come up at the right speeds. I had some driver and BIOS issues that caused some infiniband cards to only come up at half speed or 2.5gb/s vs 5.0gb/s</p>\n<h2 id=\"BIOS-updates\"><a href=\"#BIOS-updates\" class=\"headerlink\" title=\"BIOS updates\"></a>BIOS updates</h2><p>For the head nodes I was using INTEL chassis with Intel chipsets. These were very buggy and needed to be constantly updated as Intel was fixing things in the BIOS which caused great instability. Make sure all the BIOS is latest and greatest. Supermicro’s firmware’s seemed much more stable in comparison.</p>\n<h2 id=\"Protocols\"><a href=\"#Protocols\" class=\"headerlink\" title=\"Protocols.\"></a>Protocols.</h2><p>This is a very interesting topic. In a nutshell this was probably the biggest benefit. Originally I had been using Ethernet over infiniband or IPoIB which gave me very fast speeds compared to 1gb networking but no where near the speeds I would expect to see from a raid10 SSD array via 20gb infiniband. Using IPoIB also bogged down cpu’s so wasn’t ideal in my situation. So the magic really starts when you use iscsi + iser + RDMA.</p>\n<p>You still need IP based communication to do the target discovery but once the nodes all know about each other they switch to using RDMA which is way more efficient. This requires using a iscsi target software that supports iser as well as compiling the drivers for your current kernel from the Mellanox or OFED package of your choice.</p>\n<h2 id=\"Linux-Distribution\"><a href=\"#Linux-Distribution\" class=\"headerlink\" title=\"Linux Distribution\"></a>Linux Distribution</h2><p>Primarily I tested centos 6 however I also tested with Ubuntu 12.04. The best performance really depended on the kernel version.</p>\n<h2 id=\"Kernel\"><a href=\"#Kernel\" class=\"headerlink\" title=\"Kernel\"></a>Kernel</h2><p>I tested with centos 6 default and Ubuntu’s 12.04 kernels and they both gave mediocre results. I highly recommend the mainline kernel repo the mainline kernel had some significant performance patches/fixes for SSD’s in general.</p>\n<p><a href=\"http://elrepo.org/tiki/kernel-ml\" target=\"_blank\" rel=\"external\">elrepo Mainline Kernel</a></p>\n<h2 id=\"ISCSI-software\"><a href=\"#ISCSI-software\" class=\"headerlink\" title=\"ISCSI software\"></a>ISCSI software</h2><p>In Linux there are a few choices here. Originally I had been using ietd but then moved to tgtd because of support for iser RDMA which was a critical performance gain.</p>\n<p><a href=\"http://stgt.sourceforge.net/\" target=\"_blank\" rel=\"external\">stgt</a></p>\n<h2 id=\"Infiniband-software-drivers\"><a href=\"#Infiniband-software-drivers\" class=\"headerlink\" title=\"Infiniband software/drivers.\"></a>Infiniband software/drivers.</h2><p>Originally I had worked with the OFED drivers but soon realized that my Mellanox branded cards performed better when I used the firmware specifically from Mellanox it was an older revision of OFED but compiled specifically for my cards.</p>\n<p><a href=\"http://www.mellanox.com/page/products_dyn?product_family=26&amp;mtag=linux_sw_drivers\" target=\"_blank\" rel=\"external\">MLNX branded drivers</a></p>\n<p>This was a very helpful guide on the tuning recommendations I followed.<br><a href=\"http://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters.pdf\" target=\"_blank\" rel=\"external\">Performance Tuning Guide for Mellanox Network Adapters</a></p>\n<h2 id=\"sysctl-conf\"><a href=\"#sysctl-conf\" class=\"headerlink\" title=\"sysctl.conf\"></a>sysctl.conf</h2><p>The settings in sysctl.conf made significant improvements on performance.</p>\n<h2 id=\"Network-settings\"><a href=\"#Network-settings\" class=\"headerlink\" title=\"Network settings\"></a>Network settings</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">net.ipv4.tcp_timestamps=0</div><div class=\"line\">net.ipv4.tcp_sack=0</div><div class=\"line\">net.ipv4.tcp_mem=16777216 16777216 16777216</div><div class=\"line\">net.ipv4.tcp_rmem=4096 87380 16777216</div><div class=\"line\">net.ipv4.tcp_wmem=4096 65536 16777216</div><div class=\"line\">net.ipv4.tcp_low_latency = 1</div><div class=\"line\">net.core.rmem_max=16777216</div><div class=\"line\">net.core.wmem_max=16777216</div><div class=\"line\">net.core.rmem_default=16777216</div><div class=\"line\">net.core.wmem_default=16777216</div><div class=\"line\">net.core.optmem_max=16777216</div><div class=\"line\">net.core.netdev_max_backlog=250000</div></pre></td></tr></table></figure>\n<h2 id=\"Virtual-memory-settings\"><a href=\"#Virtual-memory-settings\" class=\"headerlink\" title=\"Virtual memory settings\"></a>Virtual memory settings</h2><p>Of the sysctl settings these defintily make a huge difference. Depending on the workloads of the guest machines these settings could be tweaked per your environment. I noticed significant differences in performance based on different types of workloads. YMMV</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">vm.swappiness=0</div><div class=\"line\">vm.zone_reclaim_mode=0</div><div class=\"line\">vm.dirty_ratio=10</div><div class=\"line\">vm.dirty_background_ratio=5</div></pre></td></tr></table></figure>\n<h2 id=\"IRQ-affinity\"><a href=\"#IRQ-affinity\" class=\"headerlink\" title=\"IRQ affinity\"></a>IRQ affinity</h2><p>This was a HUGE item to improve performance. First disable irqbalance and manually pin your cpu/irq affinity.<br>The Mellanox package comes with a shell script that was helpful in resetting the affinity. I used this same script to help balance between my raid card and Infiniband card. Also since I had dual a dual socket motherboard I thought it best to install the infiniband card on one PCI bus and the raid card on the other bus with the other cpu.<br>set_irq_affinity_cpulist.sh is the name of the script.</p>\n<h3 id=\"Unbalanced\"><a href=\"#Unbalanced\" class=\"headerlink\" title=\"Unbalanced\"></a>Unbalanced</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<h3 id=\"Balanced\"><a href=\"#Balanced\" class=\"headerlink\" title=\"Balanced\"></a>Balanced</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cat /proc/interrupts |grep mega</div><div class=\"line\">  80:     650586          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:     242572      87388          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:     240192          0     247210          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:      41286          0          0      42410          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:     184197          0          0          0      52479          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:     113659          0          0          0          0      58953          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:      33822          0          0          0          0          0      37659          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:      28633          0          0          0          0          0          0      35605  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<p>Some additional reading on interrupts spreading.</p>\n<p><a href=\"http://www.alexonlinux.com/msi-x-the-right-way-to-spread-interrupt-load\" target=\"_blank\" rel=\"external\">msi-x-the-right-way-to-spread-interrupt-load</a></p>\n<p><a href=\"http://www.alexonlinux.com/smp-affinity-and-proper-interrupt-handling-in-linux\" target=\"_blank\" rel=\"external\">smp-affinity-and-proper-interrupt-handling-in-linux</a></p>\n<ul>\n<li><p>Openib.conf</p>\n<p>  This file allowed me to enable and disable certain drivers. Specifically I wanted to enable the iser as well as IPoIB</p>\n</li>\n<li><p>CPU frequency/speed.</p>\n</li>\n<li><p>Raid firmware</p>\n<p>  If you update the raid firmware make sure that all the settings are set correctly still.</p>\n<p>  Also double check to make sure that the drivers are using enough interuppts.<br>  For example the stock megaraid_sas driver was only using 1 interrupt. Installing the latest driver from LSI allowed all 8 to be used.</p>\n</li>\n</ul>\n<h3 id=\"Before-and-then-after-installing-the-new-driver\"><a href=\"#Before-and-then-after-installing-the-new-driver\" class=\"headerlink\" title=\"Before and then after installing the new driver.\"></a>Before and then after installing the new driver.</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<p>Check this link at the bottom it has an attached PDF which is a really good runthrough of all the information you need.</p>\n<p><a href=\"http://mycusthelp.info/LSI/_cs/AnswerDetail.aspx?inc=8196\" target=\"_blank\" rel=\"external\">LSI tuning guide</a></p>\n<h2 id=\"C-states\"><a href=\"#C-states\" class=\"headerlink\" title=\"C-states\"></a>C-states</h2><h2 id=\"Disk-Schedulers\"><a href=\"#Disk-Schedulers\" class=\"headerlink\" title=\"Disk Schedulers\"></a>Disk Schedulers</h2><h2 id=\"Hugepages\"><a href=\"#Hugepages\" class=\"headerlink\" title=\"Hugepages\"></a>Hugepages</h2><h2 id=\"SSD-brands\"><a href=\"#SSD-brands\" class=\"headerlink\" title=\"SSD brands\"></a>SSD brands</h2><p>The samsung 840pro’s gave much much worse performance than earlier plextor m5 256gb drives I used in the past. These newer samsung drives are much slower and have a known issue with the caching on disk that conflicts with LSI firmware making them good or desktop machines but not very good in a Raid Array. I highly recommend researching this issue. Some people have worked around this by flashing differently branded firmwares onto the LSI branded cards. I wasn’t brave enough to risk bricking my raid cards so I didn’t try it.</p>\n<h2 id=\"Mount-options\"><a href=\"#Mount-options\" class=\"headerlink\" title=\"Mount options\"></a>Mount options</h2><p>Much performance can be gained as well by adding less safe mount options.<br>The best performance I saw was when I tested against ext4 with</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discard,noatime,data=writeback,barrier=0,acl,user_xattr,nobh</div></pre></td></tr></table></figure>\n<p>More to come…</p>\n","excerpt":"","more":"<p>I don’t currently have access to the original hardware I used so most of this is off memory and some notes I made.<br>Also I’ll present the caveat and warning that all these things I tested not with a view to stability for a production environment but this allowed me to get an Idea of what things I could do to eke out more performance.</p>\n<p>There were a few of basic designs I tested with. The hardware was a supermicro chassis with E5 series intel cpu’s 2x quad core 64GB ram. The raid card was LSI 9266-8i (capacitor bbu + fastpath and cachecade addons) that connected to a supermicro sas expander backplane. I tested with several different array’s of disks the most interesting were the SSD’s so for this example I was using 10 samsung 840pro 512gb ssd’s in raid 10 plus 2 hotspares. This server setup was designed to serve raw LVM based lun’s to single U nodes via 20gb Infiniband running ISCSI protocol.</p>\n<p>Here is a general list of stuff I did to maximize the performance I learned a lot about what things made the most differences. I also worked extensively with the engineers at LSI to optimize things.</p>\n<h2 id=\"Hardware\"><a href=\"#Hardware\" class=\"headerlink\" title=\"Hardware.\"></a>Hardware.</h2><h2 id=\"PCI-slots\"><a href=\"#PCI-slots\" class=\"headerlink\" title=\"PCI slots.\"></a>PCI slots.</h2><p>Its not stated anywhere in the documentation but faster is not always better. Working directly with the LSI engineers I learned that for the greatest speed and stability you should be using an 8x pci slot for the raid card. Also you want to make sure that your infiniband cards are registering at the right speeds on the PCI bus. You’ll want to use ‘lspci’ with lots of verbosity to verify that the pci cards come up at the right speeds. I had some driver and BIOS issues that caused some infiniband cards to only come up at half speed or 2.5gb/s vs 5.0gb/s</p>\n<h2 id=\"BIOS-updates\"><a href=\"#BIOS-updates\" class=\"headerlink\" title=\"BIOS updates\"></a>BIOS updates</h2><p>For the head nodes I was using INTEL chassis with Intel chipsets. These were very buggy and needed to be constantly updated as Intel was fixing things in the BIOS which caused great instability. Make sure all the BIOS is latest and greatest. Supermicro’s firmware’s seemed much more stable in comparison.</p>\n<h2 id=\"Protocols\"><a href=\"#Protocols\" class=\"headerlink\" title=\"Protocols.\"></a>Protocols.</h2><p>This is a very interesting topic. In a nutshell this was probably the biggest benefit. Originally I had been using Ethernet over infiniband or IPoIB which gave me very fast speeds compared to 1gb networking but no where near the speeds I would expect to see from a raid10 SSD array via 20gb infiniband. Using IPoIB also bogged down cpu’s so wasn’t ideal in my situation. So the magic really starts when you use iscsi + iser + RDMA.</p>\n<p>You still need IP based communication to do the target discovery but once the nodes all know about each other they switch to using RDMA which is way more efficient. This requires using a iscsi target software that supports iser as well as compiling the drivers for your current kernel from the Mellanox or OFED package of your choice.</p>\n<h2 id=\"Linux-Distribution\"><a href=\"#Linux-Distribution\" class=\"headerlink\" title=\"Linux Distribution\"></a>Linux Distribution</h2><p>Primarily I tested centos 6 however I also tested with Ubuntu 12.04. The best performance really depended on the kernel version.</p>\n<h2 id=\"Kernel\"><a href=\"#Kernel\" class=\"headerlink\" title=\"Kernel\"></a>Kernel</h2><p>I tested with centos 6 default and Ubuntu’s 12.04 kernels and they both gave mediocre results. I highly recommend the mainline kernel repo the mainline kernel had some significant performance patches/fixes for SSD’s in general.</p>\n<p><a href=\"http://elrepo.org/tiki/kernel-ml\">elrepo Mainline Kernel</a></p>\n<h2 id=\"ISCSI-software\"><a href=\"#ISCSI-software\" class=\"headerlink\" title=\"ISCSI software\"></a>ISCSI software</h2><p>In Linux there are a few choices here. Originally I had been using ietd but then moved to tgtd because of support for iser RDMA which was a critical performance gain.</p>\n<p><a href=\"http://stgt.sourceforge.net/\">stgt</a></p>\n<h2 id=\"Infiniband-software-drivers\"><a href=\"#Infiniband-software-drivers\" class=\"headerlink\" title=\"Infiniband software/drivers.\"></a>Infiniband software/drivers.</h2><p>Originally I had worked with the OFED drivers but soon realized that my Mellanox branded cards performed better when I used the firmware specifically from Mellanox it was an older revision of OFED but compiled specifically for my cards.</p>\n<p><a href=\"http://www.mellanox.com/page/products_dyn?product_family=26&amp;mtag=linux_sw_drivers\">MLNX branded drivers</a></p>\n<p>This was a very helpful guide on the tuning recommendations I followed.<br><a href=\"http://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters.pdf\">Performance Tuning Guide for Mellanox Network Adapters</a></p>\n<h2 id=\"sysctl-conf\"><a href=\"#sysctl-conf\" class=\"headerlink\" title=\"sysctl.conf\"></a>sysctl.conf</h2><p>The settings in sysctl.conf made significant improvements on performance.</p>\n<h2 id=\"Network-settings\"><a href=\"#Network-settings\" class=\"headerlink\" title=\"Network settings\"></a>Network settings</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">net.ipv4.tcp_timestamps=0</div><div class=\"line\">net.ipv4.tcp_sack=0</div><div class=\"line\">net.ipv4.tcp_mem=16777216 16777216 16777216</div><div class=\"line\">net.ipv4.tcp_rmem=4096 87380 16777216</div><div class=\"line\">net.ipv4.tcp_wmem=4096 65536 16777216</div><div class=\"line\">net.ipv4.tcp_low_latency = 1</div><div class=\"line\">net.core.rmem_max=16777216</div><div class=\"line\">net.core.wmem_max=16777216</div><div class=\"line\">net.core.rmem_default=16777216</div><div class=\"line\">net.core.wmem_default=16777216</div><div class=\"line\">net.core.optmem_max=16777216</div><div class=\"line\">net.core.netdev_max_backlog=250000</div></pre></td></tr></table></figure>\n<h2 id=\"Virtual-memory-settings\"><a href=\"#Virtual-memory-settings\" class=\"headerlink\" title=\"Virtual memory settings\"></a>Virtual memory settings</h2><p>Of the sysctl settings these defintily make a huge difference. Depending on the workloads of the guest machines these settings could be tweaked per your environment. I noticed significant differences in performance based on different types of workloads. YMMV</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">vm.swappiness=0</div><div class=\"line\">vm.zone_reclaim_mode=0</div><div class=\"line\">vm.dirty_ratio=10</div><div class=\"line\">vm.dirty_background_ratio=5</div></pre></td></tr></table></figure>\n<h2 id=\"IRQ-affinity\"><a href=\"#IRQ-affinity\" class=\"headerlink\" title=\"IRQ affinity\"></a>IRQ affinity</h2><p>This was a HUGE item to improve performance. First disable irqbalance and manually pin your cpu/irq affinity.<br>The Mellanox package comes with a shell script that was helpful in resetting the affinity. I used this same script to help balance between my raid card and Infiniband card. Also since I had dual a dual socket motherboard I thought it best to install the infiniband card on one PCI bus and the raid card on the other bus with the other cpu.<br>set_irq_affinity_cpulist.sh is the name of the script.</p>\n<h3 id=\"Unbalanced\"><a href=\"#Unbalanced\" class=\"headerlink\" title=\"Unbalanced\"></a>Unbalanced</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<h3 id=\"Balanced\"><a href=\"#Balanced\" class=\"headerlink\" title=\"Balanced\"></a>Balanced</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cat /proc/interrupts |grep mega</div><div class=\"line\">  80:     650586          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:     242572      87388          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:     240192          0     247210          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:      41286          0          0      42410          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:     184197          0          0          0      52479          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:     113659          0          0          0          0      58953          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:      33822          0          0          0          0          0      37659          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:      28633          0          0          0          0          0          0      35605  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<p>Some additional reading on interrupts spreading.</p>\n<p><a href=\"http://www.alexonlinux.com/msi-x-the-right-way-to-spread-interrupt-load\">msi-x-the-right-way-to-spread-interrupt-load</a></p>\n<p><a href=\"http://www.alexonlinux.com/smp-affinity-and-proper-interrupt-handling-in-linux\">smp-affinity-and-proper-interrupt-handling-in-linux</a></p>\n<ul>\n<li><p>Openib.conf</p>\n<p>  This file allowed me to enable and disable certain drivers. Specifically I wanted to enable the iser as well as IPoIB</p>\n</li>\n<li><p>CPU frequency/speed.</p>\n</li>\n<li><p>Raid firmware</p>\n<p>  If you update the raid firmware make sure that all the settings are set correctly still.</p>\n<p>  Also double check to make sure that the drivers are using enough interuppts.<br>  For example the stock megaraid_sas driver was only using 1 interrupt. Installing the latest driver from LSI allowed all 8 to be used.</p>\n</li>\n</ul>\n<h3 id=\"Before-and-then-after-installing-the-new-driver\"><a href=\"#Before-and-then-after-installing-the-new-driver\" class=\"headerlink\" title=\"Before and then after installing the new driver.\"></a>Before and then after installing the new driver.</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<p>Check this link at the bottom it has an attached PDF which is a really good runthrough of all the information you need.</p>\n<p><a href=\"http://mycusthelp.info/LSI/_cs/AnswerDetail.aspx?inc=8196\">LSI tuning guide</a></p>\n<h2 id=\"C-states\"><a href=\"#C-states\" class=\"headerlink\" title=\"C-states\"></a>C-states</h2><h2 id=\"Disk-Schedulers\"><a href=\"#Disk-Schedulers\" class=\"headerlink\" title=\"Disk Schedulers\"></a>Disk Schedulers</h2><h2 id=\"Hugepages\"><a href=\"#Hugepages\" class=\"headerlink\" title=\"Hugepages\"></a>Hugepages</h2><h2 id=\"SSD-brands\"><a href=\"#SSD-brands\" class=\"headerlink\" title=\"SSD brands\"></a>SSD brands</h2><p>The samsung 840pro’s gave much much worse performance than earlier plextor m5 256gb drives I used in the past. These newer samsung drives are much slower and have a known issue with the caching on disk that conflicts with LSI firmware making them good or desktop machines but not very good in a Raid Array. I highly recommend researching this issue. Some people have worked around this by flashing differently branded firmwares onto the LSI branded cards. I wasn’t brave enough to risk bricking my raid cards so I didn’t try it.</p>\n<h2 id=\"Mount-options\"><a href=\"#Mount-options\" class=\"headerlink\" title=\"Mount options\"></a>Mount options</h2><p>Much performance can be gained as well by adding less safe mount options.<br>The best performance I saw was when I tested against ext4 with</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">discard,noatime,data=writeback,barrier=0,acl,user_xattr,nobh</div></pre></td></tr></table></figure>\n<p>More to come…</p>\n"},{"title":"BASH tricks","date":"2016-08-02T21:11:47.000Z","_content":"\n# Just a bunch of bash tricks i’ve picked up.\n\nSave a backup copy of a file with a datestamp.\n\n``` bash\ncp script.sh script.sh.$(date +%Y%m%d%H%M)\n```\n\nGenerate a random string maybe for api key or password.\n\n``` bash\ncat /dev/urandom | env LC_CTYPE=C tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1\n```\n\nFind empty directories.\n\n``` bash\nfind . -mindepth 1 -maxdepth 1 -type d -empty\n```\n\nList processes being used by remote terminals and then show the files that may be opened by them. Good for tracking down what another ssh user might be doing .\n\n``` bash\nfor i in $(ps aux |grep pts |awk '{print $2}');do lsof -p $i;done\n```\n\ngrep out IP addresses from a log file.\n\n``` bash\ngrep -E -o '(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)' access.log\n```\n\nFping to show unused IP’s on a subnet.\n\n``` bash\nfping -r1 -g 192.168.1.0/24 2> /dev/null | grep unreachable | cut -f1 -d' '\n```\n\narping a /24 subnet to find alive hosts.\n\n``` bash\nfor i in `seq 1 254` ; do arping -c 1 192.168.1.$i | grep reply ; done\n```\n\n","source":"_posts/BASH-tricks.md","raw":"---\ntitle: BASH tricks\ndate: 2016-08-02 14:11:47\ntags:\n---\n\n# Just a bunch of bash tricks i’ve picked up.\n\nSave a backup copy of a file with a datestamp.\n\n``` bash\ncp script.sh script.sh.$(date +%Y%m%d%H%M)\n```\n\nGenerate a random string maybe for api key or password.\n\n``` bash\ncat /dev/urandom | env LC_CTYPE=C tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1\n```\n\nFind empty directories.\n\n``` bash\nfind . -mindepth 1 -maxdepth 1 -type d -empty\n```\n\nList processes being used by remote terminals and then show the files that may be opened by them. Good for tracking down what another ssh user might be doing .\n\n``` bash\nfor i in $(ps aux |grep pts |awk '{print $2}');do lsof -p $i;done\n```\n\ngrep out IP addresses from a log file.\n\n``` bash\ngrep -E -o '(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)' access.log\n```\n\nFping to show unused IP’s on a subnet.\n\n``` bash\nfping -r1 -g 192.168.1.0/24 2> /dev/null | grep unreachable | cut -f1 -d' '\n```\n\narping a /24 subnet to find alive hosts.\n\n``` bash\nfor i in `seq 1 254` ; do arping -c 1 192.168.1.$i | grep reply ; done\n```\n\n","slug":"BASH-tricks","published":1,"updated":"2016-08-02T21:19:27.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1budd0003hrtflpg70lqk","content":"<h1 id=\"Just-a-bunch-of-bash-tricks-i’ve-picked-up\"><a href=\"#Just-a-bunch-of-bash-tricks-i’ve-picked-up\" class=\"headerlink\" title=\"Just a bunch of bash tricks i’ve picked up.\"></a>Just a bunch of bash tricks i’ve picked up.</h1><p>Save a backup copy of a file with a datestamp.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp script.sh script.sh.$(date +%Y%m%d%H%M)</div></pre></td></tr></table></figure>\n<p>Generate a random string maybe for api key or password.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat /dev/urandom | env LC_CTYPE=C tr -dc <span class=\"string\">'a-zA-Z0-9'</span> | fold -w 32 | head -n 1</div></pre></td></tr></table></figure>\n<p>Find empty directories.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -mindepth 1 -maxdepth 1 -type d -empty</div></pre></td></tr></table></figure>\n<p>List processes being used by remote terminals and then show the files that may be opened by them. Good for tracking down what another ssh user might be doing .</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> $(ps aux |grep pts |awk <span class=\"string\">'&#123;print $2&#125;'</span>);<span class=\"keyword\">do</span> lsof -p <span class=\"variable\">$i</span>;<span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n<p>grep out IP addresses from a log file.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">grep -E -o <span class=\"string\">'(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)'</span> access.log</div></pre></td></tr></table></figure>\n<p>Fping to show unused IP’s on a subnet.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">fping -r1 -g 192.168.1.0/24 2&gt; /dev/null | grep unreachable | cut <span class=\"_\">-f</span>1 <span class=\"_\">-d</span><span class=\"string\">' '</span></div></pre></td></tr></table></figure>\n<p>arping a /24 subnet to find alive hosts.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> `seq 1 254` ; <span class=\"keyword\">do</span> arping -c 1 192.168.1.<span class=\"variable\">$i</span> | grep reply ; <span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n","excerpt":"","more":"<h1 id=\"Just-a-bunch-of-bash-tricks-i’ve-picked-up\"><a href=\"#Just-a-bunch-of-bash-tricks-i’ve-picked-up\" class=\"headerlink\" title=\"Just a bunch of bash tricks i’ve picked up.\"></a>Just a bunch of bash tricks i’ve picked up.</h1><p>Save a backup copy of a file with a datestamp.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp script.sh script.sh.$(date +%Y%m%d%H%M)</div></pre></td></tr></table></figure>\n<p>Generate a random string maybe for api key or password.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat /dev/urandom | env LC_CTYPE=C tr -dc <span class=\"string\">'a-zA-Z0-9'</span> | fold -w 32 | head -n 1</div></pre></td></tr></table></figure>\n<p>Find empty directories.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -mindepth 1 -maxdepth 1 -type d -empty</div></pre></td></tr></table></figure>\n<p>List processes being used by remote terminals and then show the files that may be opened by them. Good for tracking down what another ssh user might be doing .</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> $(ps aux |grep pts |awk <span class=\"string\">'&#123;print $2&#125;'</span>);<span class=\"keyword\">do</span> lsof -p <span class=\"variable\">$i</span>;<span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n<p>grep out IP addresses from a log file.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">grep -E -o <span class=\"string\">'(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)'</span> access.log</div></pre></td></tr></table></figure>\n<p>Fping to show unused IP’s on a subnet.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">fping -r1 -g 192.168.1.0/24 2&gt; /dev/null | grep unreachable | cut <span class=\"_\">-f</span>1 <span class=\"_\">-d</span><span class=\"string\">' '</span></div></pre></td></tr></table></figure>\n<p>arping a /24 subnet to find alive hosts.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> `seq 1 254` ; <span class=\"keyword\">do</span> arping -c 1 192.168.1.<span class=\"variable\">$i</span> | grep reply ; <span class=\"keyword\">done</span></div></pre></td></tr></table></figure>\n"},{"title":"Tricks for finding directory space usage.","date":"2016-07-14T21:21:36.000Z","_content":"\n\n# Tricks for finding directory space usage.\n\n``` bash\nfind . -iname \"*regex\" -printf \"%s\\n\" | awk '{f+=$1}END{print f/(1024 *1024 * 1024),\"GB\"}'\n```\n\n``` bash\nfind . -iname \"*.regex\" -printf \"%s\\n\" | awk '{f+=$1}END{print f}'\n```\n\nanother way.\n\n``` bash\nfind -name \\*.regex  -print0 | du -ch --files0-from=- |tail -1\n```\n\n``` bash\ndu -ch -b --max-depth=1 |sort -n|awk '{ print $1/(1024 *1024 * 1024),\"gb\", $2 }'\n```\n\nHeres almost the same command excluding anything requiring special notation close to zero.\n\n``` bash\ndu -ch -b --max-depth=1 |sort -n|awk '{ print $1/(1024 *1024 * 1024),\"gb\", $2 }' |grep -v e-0\n```\n\nanother way.\n\n``` bash\ndu -h | perl -e 'sub h{%h=(K=>10,M=>20,G=>30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h{$u}}print sort{h($b)<=>h($a)}<>;'\n```\n\nanother way.\n\n``` bash\ndu -ch --max-depth=1 --time | perl -e 'sub h{%h=(K=>10,M=>20,G=>30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h{$u}}print sort{h($b)<=>h($a)}<>;'\n```\n\n","source":"_posts/Tricks-for-finding-directory-space-usage.md","raw":"---\ntitle: Tricks for finding directory space usage.\ndate: 2016-07-14 14:21:36\ntags:\n---\n\n\n# Tricks for finding directory space usage.\n\n``` bash\nfind . -iname \"*regex\" -printf \"%s\\n\" | awk '{f+=$1}END{print f/(1024 *1024 * 1024),\"GB\"}'\n```\n\n``` bash\nfind . -iname \"*.regex\" -printf \"%s\\n\" | awk '{f+=$1}END{print f}'\n```\n\nanother way.\n\n``` bash\nfind -name \\*.regex  -print0 | du -ch --files0-from=- |tail -1\n```\n\n``` bash\ndu -ch -b --max-depth=1 |sort -n|awk '{ print $1/(1024 *1024 * 1024),\"gb\", $2 }'\n```\n\nHeres almost the same command excluding anything requiring special notation close to zero.\n\n``` bash\ndu -ch -b --max-depth=1 |sort -n|awk '{ print $1/(1024 *1024 * 1024),\"gb\", $2 }' |grep -v e-0\n```\n\nanother way.\n\n``` bash\ndu -h | perl -e 'sub h{%h=(K=>10,M=>20,G=>30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h{$u}}print sort{h($b)<=>h($a)}<>;'\n```\n\nanother way.\n\n``` bash\ndu -ch --max-depth=1 --time | perl -e 'sub h{%h=(K=>10,M=>20,G=>30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h{$u}}print sort{h($b)<=>h($a)}<>;'\n```\n\n","slug":"Tricks-for-finding-directory-space-usage","published":1,"updated":"2016-08-02T21:25:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1bude0004hrtflftv7y66","content":"<h1 id=\"Tricks-for-finding-directory-space-usage\"><a href=\"#Tricks-for-finding-directory-space-usage\" class=\"headerlink\" title=\"Tricks for finding directory space usage.\"></a>Tricks for finding directory space usage.</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -iname <span class=\"string\">\"*regex\"</span> -printf <span class=\"string\">\"%s\\n\"</span> | awk <span class=\"string\">'&#123;f+=$1&#125;END&#123;print f/(1024 *1024 * 1024),\"GB\"&#125;'</span></div></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -iname <span class=\"string\">\"*.regex\"</span> -printf <span class=\"string\">\"%s\\n\"</span> | awk <span class=\"string\">'&#123;f+=$1&#125;END&#123;print f&#125;'</span></div></pre></td></tr></table></figure>\n<p>another way.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find -name \\*.regex  -print0 | du -ch --files0-from=- |tail -1</div></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -ch -b --max-depth=1 |sort -n|awk <span class=\"string\">'&#123; print $1/(1024 *1024 * 1024),\"gb\", $2 &#125;'</span></div></pre></td></tr></table></figure>\n<p>Heres almost the same command excluding anything requiring special notation close to zero.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -ch -b --max-depth=1 |sort -n|awk <span class=\"string\">'&#123; print $1/(1024 *1024 * 1024),\"gb\", $2 &#125;'</span> |grep -v e-0</div></pre></td></tr></table></figure>\n<p>another way.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -h | perl <span class=\"_\">-e</span> <span class=\"string\">'sub h&#123;%h=(K=&gt;10,M=&gt;20,G=&gt;30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h&#123;$u&#125;&#125;print sort&#123;h($b)&lt;=&gt;h($a)&#125;&lt;&gt;;'</span></div></pre></td></tr></table></figure>\n<p>another way.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -ch --max-depth=1 --time | perl <span class=\"_\">-e</span> <span class=\"string\">'sub h&#123;%h=(K=&gt;10,M=&gt;20,G=&gt;30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h&#123;$u&#125;&#125;print sort&#123;h($b)&lt;=&gt;h($a)&#125;&lt;&gt;;'</span></div></pre></td></tr></table></figure>\n","excerpt":"","more":"<h1 id=\"Tricks-for-finding-directory-space-usage\"><a href=\"#Tricks-for-finding-directory-space-usage\" class=\"headerlink\" title=\"Tricks for finding directory space usage.\"></a>Tricks for finding directory space usage.</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -iname <span class=\"string\">\"*regex\"</span> -printf <span class=\"string\">\"%s\\n\"</span> | awk <span class=\"string\">'&#123;f+=$1&#125;END&#123;print f/(1024 *1024 * 1024),\"GB\"&#125;'</span></div></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -iname <span class=\"string\">\"*.regex\"</span> -printf <span class=\"string\">\"%s\\n\"</span> | awk <span class=\"string\">'&#123;f+=$1&#125;END&#123;print f&#125;'</span></div></pre></td></tr></table></figure>\n<p>another way.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find -name \\*.regex  -print0 | du -ch --files0-from=- |tail -1</div></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -ch -b --max-depth=1 |sort -n|awk <span class=\"string\">'&#123; print $1/(1024 *1024 * 1024),\"gb\", $2 &#125;'</span></div></pre></td></tr></table></figure>\n<p>Heres almost the same command excluding anything requiring special notation close to zero.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -ch -b --max-depth=1 |sort -n|awk <span class=\"string\">'&#123; print $1/(1024 *1024 * 1024),\"gb\", $2 &#125;'</span> |grep -v e-0</div></pre></td></tr></table></figure>\n<p>another way.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -h | perl <span class=\"_\">-e</span> <span class=\"string\">'sub h&#123;%h=(K=&gt;10,M=&gt;20,G=&gt;30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h&#123;$u&#125;&#125;print sort&#123;h($b)&lt;=&gt;h($a)&#125;&lt;&gt;;'</span></div></pre></td></tr></table></figure>\n<p>another way.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">du -ch --max-depth=1 --time | perl <span class=\"_\">-e</span> <span class=\"string\">'sub h&#123;%h=(K=&gt;10,M=&gt;20,G=&gt;30);($n,$u)=shift=~/([0-9.]+)(\\D)/;return $n*2**$h&#123;$u&#125;&#125;print sort&#123;h($b)&lt;=&gt;h($a)&#125;&lt;&gt;;'</span></div></pre></td></tr></table></figure>\n"},{"title":"serverless docker","date":"2016-07-25T04:39:25.000Z","_content":"\n## Serverless Docker... or stream processing with docker using golang.\n\nAt dockercon I saw a 'cool hack' they called [server-less docker](https://github.com/bfirsh/serverless-docker).  Basically the idea is to use containers as functions in programs instead of using containers as servers.  \n\nThis brings back the concept of [cgi](https://en.wikipedia.org/wiki/Common_Gateway_Interface).  Further on the idea of server-less docker is to create a program and inside the program functions call out to containers to do the work.\n\nInstead of needing to maintain a huge cluster of servers for a particular purpose you can have raw compute available as a swarm cluster and just utilize it as necessary for whatever computation you need.  These functions can scale as much as you need on demand.\n\nIn my experiments I got familiar with the following golang docker libraries.\n\n- [go-dockerclient](https://github.com/fsouza/go-dockerclient)\n- [go-dexec](https://github.com/ahmetalpbalkan/go-dexec)\n\n### go-dexec\n\nThis is a library to emulate most of the functionality with some exceptions to the exec library for calling functions and attaching to the cmd inputs and outputs. \n\n### go-dockerclient\n\nThis is the best docker client library for golang.  Pretty much if you are doing any work with the docker api you'll want to use this library.  \n\n\nOk so in comes my project called [go-hydra](https://github.com/benoahriz/go-hydra).  I have a few goals in  my experiments.  \n\nOne was to create an [unoconv](https://github.com/dagwieers/unoconv) container that can take stdin and produce stdout that is usable.  \n\nAnother goal was to get familiar with the go http or mux package as well as go-dexec.\n\nThe goal of go-hydra is to be a front end http api/server that serves client requests that get processed on the back end which would normally be a docker swarm cluster.  Each function runs a separate container and sends the response back to the client.  The containers would primarily use stdin and stdout if possible.\n\n## The first piece.\n\nIn my use case I wanted to create a docker container that would take stdin and produce stdout of raw bytes.   This would allow you to do something like the following.\n\n``` bash\necho \"test\" |docker run unoconv2 --stdin --stdout f pdf > testpdf.pdf\n```\n\nor\n\n```bash\ncat test/Checklist-Ubuntu_v7.pdf| docker run unoconv2 --stdin --stdout --format=txt > file.txt\n```\n\nThis was a bit of a headache as the standard versions of unoconv in ubuntu 14.04 do not have support for stdin.  This means no streaming input :(\n\nI had to basically build it off the latest code in the repo which has the support for stdin. See the dockerfile for details.  [Link](https://github.com/benoahriz/go-hydra/blob/master/Dockerfile)\n\nAlso unrelated to my hack projects main goals I also got a proof of concept apt-cacher-ng detector for build scripts which can greatly reduce the time needed for building container images that use apt packages.\n\n## golang http\n\nMy second implementation experiment was to create a simple rudimentary http server that would execute some proof of concept code using the containers.\n\nFirst I implemented a simple uploader... in theory my goal is to not need the uploader at all and stream the data direct from the client.  However one step at a time.\n\n```bash\ngo run main.go\n```\n\nThen visit this url.  http://localhost:8080/upload\n\nYou can use this to simply upload your file to be processed to the http server.\n\nThen once the file is uploaded.\n\n```bash\n curl \"http://localhost:8080/toupper/txt?filename=README.md\"\n```\n\nThe result you'll see is on the console of the web server.  This was a simple example not using the unoconv script but using simple 'tr' to convert the text to uppercase.\n\nThe way this is currently sort of working is that i'm reading the file in and then sending it to stdin to the container then capturing the result in stdout of the app.  The real goal was to get the output streamed into the body of the response but there are some shortcomings with the dexec library.\n\nThere are some major issues with these experiments.  Firstly that the unoconv library doesn't always work as expected.  I didn't go into  depth trying to figure out what was wrong with it.  So instead I continued with using the tr example on the dexec readme.  The other issues I ran into were the implementation of stdinpipe and stdoutpipe in dexec only allow you to use one at a time and I will need to dig deeper to figure out how to get that to work right.\n","source":"_posts/Serverless-Docker.md","raw":"---\ntitle: serverless docker\ndate: 2016-07-24 21:39:25\ntags:\n  - docker\n  - golang\n  - go-dockerclient\n  - go-dexec\n---\n\n## Serverless Docker... or stream processing with docker using golang.\n\nAt dockercon I saw a 'cool hack' they called [server-less docker](https://github.com/bfirsh/serverless-docker).  Basically the idea is to use containers as functions in programs instead of using containers as servers.  \n\nThis brings back the concept of [cgi](https://en.wikipedia.org/wiki/Common_Gateway_Interface).  Further on the idea of server-less docker is to create a program and inside the program functions call out to containers to do the work.\n\nInstead of needing to maintain a huge cluster of servers for a particular purpose you can have raw compute available as a swarm cluster and just utilize it as necessary for whatever computation you need.  These functions can scale as much as you need on demand.\n\nIn my experiments I got familiar with the following golang docker libraries.\n\n- [go-dockerclient](https://github.com/fsouza/go-dockerclient)\n- [go-dexec](https://github.com/ahmetalpbalkan/go-dexec)\n\n### go-dexec\n\nThis is a library to emulate most of the functionality with some exceptions to the exec library for calling functions and attaching to the cmd inputs and outputs. \n\n### go-dockerclient\n\nThis is the best docker client library for golang.  Pretty much if you are doing any work with the docker api you'll want to use this library.  \n\n\nOk so in comes my project called [go-hydra](https://github.com/benoahriz/go-hydra).  I have a few goals in  my experiments.  \n\nOne was to create an [unoconv](https://github.com/dagwieers/unoconv) container that can take stdin and produce stdout that is usable.  \n\nAnother goal was to get familiar with the go http or mux package as well as go-dexec.\n\nThe goal of go-hydra is to be a front end http api/server that serves client requests that get processed on the back end which would normally be a docker swarm cluster.  Each function runs a separate container and sends the response back to the client.  The containers would primarily use stdin and stdout if possible.\n\n## The first piece.\n\nIn my use case I wanted to create a docker container that would take stdin and produce stdout of raw bytes.   This would allow you to do something like the following.\n\n``` bash\necho \"test\" |docker run unoconv2 --stdin --stdout f pdf > testpdf.pdf\n```\n\nor\n\n```bash\ncat test/Checklist-Ubuntu_v7.pdf| docker run unoconv2 --stdin --stdout --format=txt > file.txt\n```\n\nThis was a bit of a headache as the standard versions of unoconv in ubuntu 14.04 do not have support for stdin.  This means no streaming input :(\n\nI had to basically build it off the latest code in the repo which has the support for stdin. See the dockerfile for details.  [Link](https://github.com/benoahriz/go-hydra/blob/master/Dockerfile)\n\nAlso unrelated to my hack projects main goals I also got a proof of concept apt-cacher-ng detector for build scripts which can greatly reduce the time needed for building container images that use apt packages.\n\n## golang http\n\nMy second implementation experiment was to create a simple rudimentary http server that would execute some proof of concept code using the containers.\n\nFirst I implemented a simple uploader... in theory my goal is to not need the uploader at all and stream the data direct from the client.  However one step at a time.\n\n```bash\ngo run main.go\n```\n\nThen visit this url.  http://localhost:8080/upload\n\nYou can use this to simply upload your file to be processed to the http server.\n\nThen once the file is uploaded.\n\n```bash\n curl \"http://localhost:8080/toupper/txt?filename=README.md\"\n```\n\nThe result you'll see is on the console of the web server.  This was a simple example not using the unoconv script but using simple 'tr' to convert the text to uppercase.\n\nThe way this is currently sort of working is that i'm reading the file in and then sending it to stdin to the container then capturing the result in stdout of the app.  The real goal was to get the output streamed into the body of the response but there are some shortcomings with the dexec library.\n\nThere are some major issues with these experiments.  Firstly that the unoconv library doesn't always work as expected.  I didn't go into  depth trying to figure out what was wrong with it.  So instead I continued with using the tr example on the dexec readme.  The other issues I ran into were the implementation of stdinpipe and stdoutpipe in dexec only allow you to use one at a time and I will need to dig deeper to figure out how to get that to work right.\n","slug":"Serverless-Docker","published":1,"updated":"2016-08-02T21:11:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1budg0006hrtfu97vgs5p","content":"<h2 id=\"Serverless-Docker…-or-stream-processing-with-docker-using-golang\"><a href=\"#Serverless-Docker…-or-stream-processing-with-docker-using-golang\" class=\"headerlink\" title=\"Serverless Docker… or stream processing with docker using golang.\"></a>Serverless Docker… or stream processing with docker using golang.</h2><p>At dockercon I saw a ‘cool hack’ they called <a href=\"https://github.com/bfirsh/serverless-docker\" target=\"_blank\" rel=\"external\">server-less docker</a>.  Basically the idea is to use containers as functions in programs instead of using containers as servers.  </p>\n<p>This brings back the concept of <a href=\"https://en.wikipedia.org/wiki/Common_Gateway_Interface\" target=\"_blank\" rel=\"external\">cgi</a>.  Further on the idea of server-less docker is to create a program and inside the program functions call out to containers to do the work.</p>\n<p>Instead of needing to maintain a huge cluster of servers for a particular purpose you can have raw compute available as a swarm cluster and just utilize it as necessary for whatever computation you need.  These functions can scale as much as you need on demand.</p>\n<p>In my experiments I got familiar with the following golang docker libraries.</p>\n<ul>\n<li><a href=\"https://github.com/fsouza/go-dockerclient\" target=\"_blank\" rel=\"external\">go-dockerclient</a></li>\n<li><a href=\"https://github.com/ahmetalpbalkan/go-dexec\" target=\"_blank\" rel=\"external\">go-dexec</a></li>\n</ul>\n<h3 id=\"go-dexec\"><a href=\"#go-dexec\" class=\"headerlink\" title=\"go-dexec\"></a>go-dexec</h3><p>This is a library to emulate most of the functionality with some exceptions to the exec library for calling functions and attaching to the cmd inputs and outputs. </p>\n<h3 id=\"go-dockerclient\"><a href=\"#go-dockerclient\" class=\"headerlink\" title=\"go-dockerclient\"></a>go-dockerclient</h3><p>This is the best docker client library for golang.  Pretty much if you are doing any work with the docker api you’ll want to use this library.  </p>\n<p>Ok so in comes my project called <a href=\"https://github.com/benoahriz/go-hydra\" target=\"_blank\" rel=\"external\">go-hydra</a>.  I have a few goals in  my experiments.  </p>\n<p>One was to create an <a href=\"https://github.com/dagwieers/unoconv\" target=\"_blank\" rel=\"external\">unoconv</a> container that can take stdin and produce stdout that is usable.  </p>\n<p>Another goal was to get familiar with the go http or mux package as well as go-dexec.</p>\n<p>The goal of go-hydra is to be a front end http api/server that serves client requests that get processed on the back end which would normally be a docker swarm cluster.  Each function runs a separate container and sends the response back to the client.  The containers would primarily use stdin and stdout if possible.</p>\n<h2 id=\"The-first-piece\"><a href=\"#The-first-piece\" class=\"headerlink\" title=\"The first piece.\"></a>The first piece.</h2><p>In my use case I wanted to create a docker container that would take stdin and produce stdout of raw bytes.   This would allow you to do something like the following.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"test\"</span> |docker run unoconv2 --stdin --stdout f pdf &gt; testpdf.pdf</div></pre></td></tr></table></figure>\n<p>or</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat <span class=\"built_in\">test</span>/Checklist-Ubuntu_v7.pdf| docker run unoconv2 --stdin --stdout --format=txt &gt; file.txt</div></pre></td></tr></table></figure>\n<p>This was a bit of a headache as the standard versions of unoconv in ubuntu 14.04 do not have support for stdin.  This means no streaming input :(</p>\n<p>I had to basically build it off the latest code in the repo which has the support for stdin. See the dockerfile for details.  <a href=\"https://github.com/benoahriz/go-hydra/blob/master/Dockerfile\" target=\"_blank\" rel=\"external\">Link</a></p>\n<p>Also unrelated to my hack projects main goals I also got a proof of concept apt-cacher-ng detector for build scripts which can greatly reduce the time needed for building container images that use apt packages.</p>\n<h2 id=\"golang-http\"><a href=\"#golang-http\" class=\"headerlink\" title=\"golang http\"></a>golang http</h2><p>My second implementation experiment was to create a simple rudimentary http server that would execute some proof of concept code using the containers.</p>\n<p>First I implemented a simple uploader… in theory my goal is to not need the uploader at all and stream the data direct from the client.  However one step at a time.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">go run main.go</div></pre></td></tr></table></figure>\n<p>Then visit this url.  <a href=\"http://localhost:8080/upload\" target=\"_blank\" rel=\"external\">http://localhost:8080/upload</a></p>\n<p>You can use this to simply upload your file to be processed to the http server.</p>\n<p>Then once the file is uploaded.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl <span class=\"string\">\"http://localhost:8080/toupper/txt?filename=README.md\"</span></div></pre></td></tr></table></figure>\n<p>The result you’ll see is on the console of the web server.  This was a simple example not using the unoconv script but using simple ‘tr’ to convert the text to uppercase.</p>\n<p>The way this is currently sort of working is that i’m reading the file in and then sending it to stdin to the container then capturing the result in stdout of the app.  The real goal was to get the output streamed into the body of the response but there are some shortcomings with the dexec library.</p>\n<p>There are some major issues with these experiments.  Firstly that the unoconv library doesn’t always work as expected.  I didn’t go into  depth trying to figure out what was wrong with it.  So instead I continued with using the tr example on the dexec readme.  The other issues I ran into were the implementation of stdinpipe and stdoutpipe in dexec only allow you to use one at a time and I will need to dig deeper to figure out how to get that to work right.</p>\n","excerpt":"","more":"<h2 id=\"Serverless-Docker…-or-stream-processing-with-docker-using-golang\"><a href=\"#Serverless-Docker…-or-stream-processing-with-docker-using-golang\" class=\"headerlink\" title=\"Serverless Docker… or stream processing with docker using golang.\"></a>Serverless Docker… or stream processing with docker using golang.</h2><p>At dockercon I saw a ‘cool hack’ they called <a href=\"https://github.com/bfirsh/serverless-docker\">server-less docker</a>.  Basically the idea is to use containers as functions in programs instead of using containers as servers.  </p>\n<p>This brings back the concept of <a href=\"https://en.wikipedia.org/wiki/Common_Gateway_Interface\">cgi</a>.  Further on the idea of server-less docker is to create a program and inside the program functions call out to containers to do the work.</p>\n<p>Instead of needing to maintain a huge cluster of servers for a particular purpose you can have raw compute available as a swarm cluster and just utilize it as necessary for whatever computation you need.  These functions can scale as much as you need on demand.</p>\n<p>In my experiments I got familiar with the following golang docker libraries.</p>\n<ul>\n<li><a href=\"https://github.com/fsouza/go-dockerclient\">go-dockerclient</a></li>\n<li><a href=\"https://github.com/ahmetalpbalkan/go-dexec\">go-dexec</a></li>\n</ul>\n<h3 id=\"go-dexec\"><a href=\"#go-dexec\" class=\"headerlink\" title=\"go-dexec\"></a>go-dexec</h3><p>This is a library to emulate most of the functionality with some exceptions to the exec library for calling functions and attaching to the cmd inputs and outputs. </p>\n<h3 id=\"go-dockerclient\"><a href=\"#go-dockerclient\" class=\"headerlink\" title=\"go-dockerclient\"></a>go-dockerclient</h3><p>This is the best docker client library for golang.  Pretty much if you are doing any work with the docker api you’ll want to use this library.  </p>\n<p>Ok so in comes my project called <a href=\"https://github.com/benoahriz/go-hydra\">go-hydra</a>.  I have a few goals in  my experiments.  </p>\n<p>One was to create an <a href=\"https://github.com/dagwieers/unoconv\">unoconv</a> container that can take stdin and produce stdout that is usable.  </p>\n<p>Another goal was to get familiar with the go http or mux package as well as go-dexec.</p>\n<p>The goal of go-hydra is to be a front end http api/server that serves client requests that get processed on the back end which would normally be a docker swarm cluster.  Each function runs a separate container and sends the response back to the client.  The containers would primarily use stdin and stdout if possible.</p>\n<h2 id=\"The-first-piece\"><a href=\"#The-first-piece\" class=\"headerlink\" title=\"The first piece.\"></a>The first piece.</h2><p>In my use case I wanted to create a docker container that would take stdin and produce stdout of raw bytes.   This would allow you to do something like the following.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"test\"</span> |docker run unoconv2 --stdin --stdout f pdf &gt; testpdf.pdf</div></pre></td></tr></table></figure>\n<p>or</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat <span class=\"built_in\">test</span>/Checklist-Ubuntu_v7.pdf| docker run unoconv2 --stdin --stdout --format=txt &gt; file.txt</div></pre></td></tr></table></figure>\n<p>This was a bit of a headache as the standard versions of unoconv in ubuntu 14.04 do not have support for stdin.  This means no streaming input :(</p>\n<p>I had to basically build it off the latest code in the repo which has the support for stdin. See the dockerfile for details.  <a href=\"https://github.com/benoahriz/go-hydra/blob/master/Dockerfile\">Link</a></p>\n<p>Also unrelated to my hack projects main goals I also got a proof of concept apt-cacher-ng detector for build scripts which can greatly reduce the time needed for building container images that use apt packages.</p>\n<h2 id=\"golang-http\"><a href=\"#golang-http\" class=\"headerlink\" title=\"golang http\"></a>golang http</h2><p>My second implementation experiment was to create a simple rudimentary http server that would execute some proof of concept code using the containers.</p>\n<p>First I implemented a simple uploader… in theory my goal is to not need the uploader at all and stream the data direct from the client.  However one step at a time.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">go run main.go</div></pre></td></tr></table></figure>\n<p>Then visit this url.  <a href=\"http://localhost:8080/upload\">http://localhost:8080/upload</a></p>\n<p>You can use this to simply upload your file to be processed to the http server.</p>\n<p>Then once the file is uploaded.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl <span class=\"string\">\"http://localhost:8080/toupper/txt?filename=README.md\"</span></div></pre></td></tr></table></figure>\n<p>The result you’ll see is on the console of the web server.  This was a simple example not using the unoconv script but using simple ‘tr’ to convert the text to uppercase.</p>\n<p>The way this is currently sort of working is that i’m reading the file in and then sending it to stdin to the container then capturing the result in stdout of the app.  The real goal was to get the output streamed into the body of the response but there are some shortcomings with the dexec library.</p>\n<p>There are some major issues with these experiments.  Firstly that the unoconv library doesn’t always work as expected.  I didn’t go into  depth trying to figure out what was wrong with it.  So instead I continued with using the tr example on the dexec readme.  The other issues I ran into were the implementation of stdinpipe and stdoutpipe in dexec only allow you to use one at a time and I will need to dig deeper to figure out how to get that to work right.</p>\n"},{"title":"Using Ansible to communicate with rest API","date":"2016-07-15T21:15:27.000Z","_content":"\n# Ansible to interact with a rest API\nSometimes you may want to interact with a rest api where an Ansible module doesn’t already exist. For those cases you may want to try using the uri module. Ansible already supports interacting with json so its pretty easy. Below I show an example of interacting with the Vault api. Link\n\nYou may want to use Vault in cases where there is more sensitive information that you need to ensure that it is encrypted as well as has an audit trail. Vault provides these things and they are fairly easy to setup.\n\nThis example assumes you have setup a few things first.\n\nThings you need with links to the instructions.\n\n1. [Github account with a personal access token](https://github.com/blog/1509-personal-api-tokens)\n\n2. make sure you export the token to your environment variables or hardcode it. In this example I use the lookup Ansible plugin to look up the GITHUB_TOKEN env var. ```export GITHUB_TOKEN=xxxxxxxxxxxx```\n\n3. [Vault setup to use Github as an authentication back end.](https://www.vaultproject.io/docs/auth/github.html)\n\n\nHere we check out a Vault token using our github token.\n\n``` bash\n---\n- name: ansible examples\n  hosts: localhost\n  vars:\n    github_token: \"{{ lookup('env','GITHUB_TOKEN') }}\"\n    home_directory: \"{{ lookup('env','HOME') }}\"\n    user: \"{{ lookup('env','USER') }}\"\n  tasks:\n    - name: get vault token\n      uri:\n        url: \"https://myvault.com:8200/v1/auth/github/login\"\n        method: POST\n        validate_certs: no\n        follow_redirects: all\n        body:\n          token: \"{{ github_token }}\"\n        return_content: yes\n        body_format: json\n      register: token_output\n      delegate_to: 127.0.0.1\n    - debug: var=token_output.json.auth.client_token\n\n```\n\nNow that we have a Vault token we can write values to the keystore. Notice how you can embed json directly into the yaml :)\n\n``` bash\n#     vault returns a 204 on success not 200\n    - name: use token to update a secret\n      uri:\n        url: \"https://myvault.com:8200/v1/envs/ansible_examples\"\n        method: POST\n        validate_certs: no\n        follow_redirects: all\n        HEADER_X-Vault-Token: \"{{ token_output.json.auth.client_token }}\"\n        body: \"{\n                '{{ user }}': '{{ home_directory }}'\n              }\"\n#        body:\n#          user: \"{{ home_directory }}\"\n        return_content: yes\n        body_format: json\n        status_code: 204\n      register: add_secret\n      delegate_to: 127.0.0.1\n    - debug: var=add_secret\n\n```\n\nHere we can read back the encrypted key from the vault.\n\n``` bash \n\n- name: use token to read a secret\n  uri:\n    url: \"https://myvault.com:8200/v1/envs/ansible_examples\"\n    method: GET\n    validate_certs: no\n    follow_redirects: all\n    HEADER_X-Vault-Token: \"{{ token_output.json.auth.client_token }}\"\n    return_content: yes\n    body_format: json\n  register: read_secret\n  delegate_to: 127.0.0.1\n\n- debug: var=read_secret\n- debug: \"var=read_secret.json.data.{{ user }}\"\n\n```\n\n\n\n\n\n\n\n\n","source":"_posts/Using-Ansible-to-communicate-with-rest-API.md","raw":"---\ntitle: Using Ansible to communicate with rest API\ndate: 2016-07-15 14:15:27\ntags:\n---\n\n# Ansible to interact with a rest API\nSometimes you may want to interact with a rest api where an Ansible module doesn’t already exist. For those cases you may want to try using the uri module. Ansible already supports interacting with json so its pretty easy. Below I show an example of interacting with the Vault api. Link\n\nYou may want to use Vault in cases where there is more sensitive information that you need to ensure that it is encrypted as well as has an audit trail. Vault provides these things and they are fairly easy to setup.\n\nThis example assumes you have setup a few things first.\n\nThings you need with links to the instructions.\n\n1. [Github account with a personal access token](https://github.com/blog/1509-personal-api-tokens)\n\n2. make sure you export the token to your environment variables or hardcode it. In this example I use the lookup Ansible plugin to look up the GITHUB_TOKEN env var. ```export GITHUB_TOKEN=xxxxxxxxxxxx```\n\n3. [Vault setup to use Github as an authentication back end.](https://www.vaultproject.io/docs/auth/github.html)\n\n\nHere we check out a Vault token using our github token.\n\n``` bash\n---\n- name: ansible examples\n  hosts: localhost\n  vars:\n    github_token: \"{{ lookup('env','GITHUB_TOKEN') }}\"\n    home_directory: \"{{ lookup('env','HOME') }}\"\n    user: \"{{ lookup('env','USER') }}\"\n  tasks:\n    - name: get vault token\n      uri:\n        url: \"https://myvault.com:8200/v1/auth/github/login\"\n        method: POST\n        validate_certs: no\n        follow_redirects: all\n        body:\n          token: \"{{ github_token }}\"\n        return_content: yes\n        body_format: json\n      register: token_output\n      delegate_to: 127.0.0.1\n    - debug: var=token_output.json.auth.client_token\n\n```\n\nNow that we have a Vault token we can write values to the keystore. Notice how you can embed json directly into the yaml :)\n\n``` bash\n#     vault returns a 204 on success not 200\n    - name: use token to update a secret\n      uri:\n        url: \"https://myvault.com:8200/v1/envs/ansible_examples\"\n        method: POST\n        validate_certs: no\n        follow_redirects: all\n        HEADER_X-Vault-Token: \"{{ token_output.json.auth.client_token }}\"\n        body: \"{\n                '{{ user }}': '{{ home_directory }}'\n              }\"\n#        body:\n#          user: \"{{ home_directory }}\"\n        return_content: yes\n        body_format: json\n        status_code: 204\n      register: add_secret\n      delegate_to: 127.0.0.1\n    - debug: var=add_secret\n\n```\n\nHere we can read back the encrypted key from the vault.\n\n``` bash \n\n- name: use token to read a secret\n  uri:\n    url: \"https://myvault.com:8200/v1/envs/ansible_examples\"\n    method: GET\n    validate_certs: no\n    follow_redirects: all\n    HEADER_X-Vault-Token: \"{{ token_output.json.auth.client_token }}\"\n    return_content: yes\n    body_format: json\n  register: read_secret\n  delegate_to: 127.0.0.1\n\n- debug: var=read_secret\n- debug: \"var=read_secret.json.data.{{ user }}\"\n\n```\n\n\n\n\n\n\n\n\n","slug":"Using-Ansible-to-communicate-with-rest-API","published":1,"updated":"2016-08-02T21:19:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1budi0007hrtfky2t8oht","content":"<h1 id=\"Ansible-to-interact-with-a-rest-API\"><a href=\"#Ansible-to-interact-with-a-rest-API\" class=\"headerlink\" title=\"Ansible to interact with a rest API\"></a>Ansible to interact with a rest API</h1><p>Sometimes you may want to interact with a rest api where an Ansible module doesn’t already exist. For those cases you may want to try using the uri module. Ansible already supports interacting with json so its pretty easy. Below I show an example of interacting with the Vault api. Link</p>\n<p>You may want to use Vault in cases where there is more sensitive information that you need to ensure that it is encrypted as well as has an audit trail. Vault provides these things and they are fairly easy to setup.</p>\n<p>This example assumes you have setup a few things first.</p>\n<p>Things you need with links to the instructions.</p>\n<ol>\n<li><p><a href=\"https://github.com/blog/1509-personal-api-tokens\" target=\"_blank\" rel=\"external\">Github account with a personal access token</a></p>\n</li>\n<li><p>make sure you export the token to your environment variables or hardcode it. In this example I use the lookup Ansible plugin to look up the GITHUB_TOKEN env var. <figure class=\"highlight plain\"><figcaption><span>GITHUB_TOKEN=xxxxxxxxxxxx```</span></figcaption><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">3. [Vault setup to use Github as an authentication back end.](https://www.vaultproject.io/docs/auth/github.html)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">Here we check out a Vault token using our github token.</div><div class=\"line\"></div><div class=\"line\">``` bash</div><div class=\"line\">---</div><div class=\"line\">- name: ansible examples</div><div class=\"line\">  hosts: localhost</div><div class=\"line\">  vars:</div><div class=\"line\">    github_token: &quot;&#123;&#123; lookup(&apos;env&apos;,&apos;GITHUB_TOKEN&apos;) &#125;&#125;&quot;</div><div class=\"line\">    home_directory: &quot;&#123;&#123; lookup(&apos;env&apos;,&apos;HOME&apos;) &#125;&#125;&quot;</div><div class=\"line\">    user: &quot;&#123;&#123; lookup(&apos;env&apos;,&apos;USER&apos;) &#125;&#125;&quot;</div><div class=\"line\">  tasks:</div><div class=\"line\">    - name: get vault token</div><div class=\"line\">      uri:</div><div class=\"line\">        url: &quot;https://myvault.com:8200/v1/auth/github/login&quot;</div><div class=\"line\">        method: POST</div><div class=\"line\">        validate_certs: no</div><div class=\"line\">        follow_redirects: all</div><div class=\"line\">        body:</div><div class=\"line\">          token: &quot;&#123;&#123; github_token &#125;&#125;&quot;</div><div class=\"line\">        return_content: yes</div><div class=\"line\">        body_format: json</div><div class=\"line\">      register: token_output</div><div class=\"line\">      delegate_to: 127.0.0.1</div><div class=\"line\">    - debug: var=token_output.json.auth.client_token</div></pre></td></tr></table></figure></p>\n</li>\n</ol>\n<p>Now that we have a Vault token we can write values to the keystore. Notice how you can embed json directly into the yaml :)</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#     vault returns a 204 on success not 200</span></div><div class=\"line\">    - name: use token to update a secret</div><div class=\"line\">      uri:</div><div class=\"line\">        url: <span class=\"string\">\"https://myvault.com:8200/v1/envs/ansible_examples\"</span></div><div class=\"line\">        method: POST</div><div class=\"line\">        validate_certs: no</div><div class=\"line\">        follow_redirects: all</div><div class=\"line\">        HEADER_X-Vault-Token: <span class=\"string\">\"&#123;&#123; token_output.json.auth.client_token &#125;&#125;\"</span></div><div class=\"line\">        body: <span class=\"string\">\"&#123;</span></div><div class=\"line\">                '&#123;&#123; user &#125;&#125;': '&#123;&#123; home_directory &#125;&#125;'</div><div class=\"line\">              &#125;\"</div><div class=\"line\"><span class=\"comment\">#        body:</span></div><div class=\"line\"><span class=\"comment\">#          user: \"&#123;&#123; home_directory &#125;&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">return</span>_content: yes</div><div class=\"line\">        body_format: json</div><div class=\"line\">        status_code: 204</div><div class=\"line\">      register: add_secret</div><div class=\"line\">      delegate_to: 127.0.0.1</div><div class=\"line\">    - debug: var=add_secret</div></pre></td></tr></table></figure>\n<p>Here we can read back the encrypted key from the vault.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">- name: use token to <span class=\"built_in\">read</span> a secret</div><div class=\"line\">  uri:</div><div class=\"line\">    url: <span class=\"string\">\"https://myvault.com:8200/v1/envs/ansible_examples\"</span></div><div class=\"line\">    method: GET</div><div class=\"line\">    validate_certs: no</div><div class=\"line\">    follow_redirects: all</div><div class=\"line\">    HEADER_X-Vault-Token: <span class=\"string\">\"&#123;&#123; token_output.json.auth.client_token &#125;&#125;\"</span></div><div class=\"line\">    <span class=\"built_in\">return</span>_content: yes</div><div class=\"line\">    body_format: json</div><div class=\"line\">  register: <span class=\"built_in\">read</span>_secret</div><div class=\"line\">  delegate_to: 127.0.0.1</div><div class=\"line\"></div><div class=\"line\">- debug: var=<span class=\"built_in\">read</span>_secret</div><div class=\"line\">- debug: <span class=\"string\">\"var=read_secret.json.data.&#123;&#123; user &#125;&#125;\"</span></div></pre></td></tr></table></figure>\n","excerpt":"","more":"<h1 id=\"Ansible-to-interact-with-a-rest-API\"><a href=\"#Ansible-to-interact-with-a-rest-API\" class=\"headerlink\" title=\"Ansible to interact with a rest API\"></a>Ansible to interact with a rest API</h1><p>Sometimes you may want to interact with a rest api where an Ansible module doesn’t already exist. For those cases you may want to try using the uri module. Ansible already supports interacting with json so its pretty easy. Below I show an example of interacting with the Vault api. Link</p>\n<p>You may want to use Vault in cases where there is more sensitive information that you need to ensure that it is encrypted as well as has an audit trail. Vault provides these things and they are fairly easy to setup.</p>\n<p>This example assumes you have setup a few things first.</p>\n<p>Things you need with links to the instructions.</p>\n<ol>\n<li><p><a href=\"https://github.com/blog/1509-personal-api-tokens\">Github account with a personal access token</a></p>\n</li>\n<li><p>make sure you export the token to your environment variables or hardcode it. In this example I use the lookup Ansible plugin to look up the GITHUB_TOKEN env var. <figure class=\"highlight plain\"><figcaption><span>GITHUB_TOKEN=xxxxxxxxxxxx```</span></figcaption><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">3. [Vault setup to use Github as an authentication back end.](https://www.vaultproject.io/docs/auth/github.html)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">Here we check out a Vault token using our github token.</div><div class=\"line\"></div><div class=\"line\">``` bash</div><div class=\"line\">---</div><div class=\"line\">- name: ansible examples</div><div class=\"line\">  hosts: localhost</div><div class=\"line\">  vars:</div><div class=\"line\">    github_token: &quot;&#123;&#123; lookup(&apos;env&apos;,&apos;GITHUB_TOKEN&apos;) &#125;&#125;&quot;</div><div class=\"line\">    home_directory: &quot;&#123;&#123; lookup(&apos;env&apos;,&apos;HOME&apos;) &#125;&#125;&quot;</div><div class=\"line\">    user: &quot;&#123;&#123; lookup(&apos;env&apos;,&apos;USER&apos;) &#125;&#125;&quot;</div><div class=\"line\">  tasks:</div><div class=\"line\">    - name: get vault token</div><div class=\"line\">      uri:</div><div class=\"line\">        url: &quot;https://myvault.com:8200/v1/auth/github/login&quot;</div><div class=\"line\">        method: POST</div><div class=\"line\">        validate_certs: no</div><div class=\"line\">        follow_redirects: all</div><div class=\"line\">        body:</div><div class=\"line\">          token: &quot;&#123;&#123; github_token &#125;&#125;&quot;</div><div class=\"line\">        return_content: yes</div><div class=\"line\">        body_format: json</div><div class=\"line\">      register: token_output</div><div class=\"line\">      delegate_to: 127.0.0.1</div><div class=\"line\">    - debug: var=token_output.json.auth.client_token</div></pre></td></tr></table></figure></p>\n</li>\n</ol>\n<p>Now that we have a Vault token we can write values to the keystore. Notice how you can embed json directly into the yaml :)</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#     vault returns a 204 on success not 200</span></div><div class=\"line\">    - name: use token to update a secret</div><div class=\"line\">      uri:</div><div class=\"line\">        url: <span class=\"string\">\"https://myvault.com:8200/v1/envs/ansible_examples\"</span></div><div class=\"line\">        method: POST</div><div class=\"line\">        validate_certs: no</div><div class=\"line\">        follow_redirects: all</div><div class=\"line\">        HEADER_X-Vault-Token: <span class=\"string\">\"&#123;&#123; token_output.json.auth.client_token &#125;&#125;\"</span></div><div class=\"line\">        body: <span class=\"string\">\"&#123;</div><div class=\"line\">                '&#123;&#123; user &#125;&#125;': '&#123;&#123; home_directory &#125;&#125;'</div><div class=\"line\">              &#125;\"</span></div><div class=\"line\"><span class=\"comment\">#        body:</span></div><div class=\"line\"><span class=\"comment\">#          user: \"&#123;&#123; home_directory &#125;&#125;\"</span></div><div class=\"line\">        <span class=\"built_in\">return</span>_content: yes</div><div class=\"line\">        body_format: json</div><div class=\"line\">        status_code: 204</div><div class=\"line\">      register: add_secret</div><div class=\"line\">      delegate_to: 127.0.0.1</div><div class=\"line\">    - debug: var=add_secret</div></pre></td></tr></table></figure>\n<p>Here we can read back the encrypted key from the vault.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">- name: use token to <span class=\"built_in\">read</span> a secret</div><div class=\"line\">  uri:</div><div class=\"line\">    url: <span class=\"string\">\"https://myvault.com:8200/v1/envs/ansible_examples\"</span></div><div class=\"line\">    method: GET</div><div class=\"line\">    validate_certs: no</div><div class=\"line\">    follow_redirects: all</div><div class=\"line\">    HEADER_X-Vault-Token: <span class=\"string\">\"&#123;&#123; token_output.json.auth.client_token &#125;&#125;\"</span></div><div class=\"line\">    <span class=\"built_in\">return</span>_content: yes</div><div class=\"line\">    body_format: json</div><div class=\"line\">  register: <span class=\"built_in\">read</span>_secret</div><div class=\"line\">  delegate_to: 127.0.0.1</div><div class=\"line\"></div><div class=\"line\">- debug: var=<span class=\"built_in\">read</span>_secret</div><div class=\"line\">- debug: <span class=\"string\">\"var=read_secret.json.data.&#123;&#123; user &#125;&#125;\"</span></div></pre></td></tr></table></figure>\n"},{"title":"apt-cacher-ng with docker builds","date":"2016-07-20T21:05:46.000Z","_content":"\n# apt-cacher-ng with docker builds\n\nWorking with docker on a laptop testing configuration of containers has some of the same annoyances as working with other configuration managment tools and testing frameworks like test-kitchen, chef, ansible etc…\n\nIt takes forever to download dependencies. I might test some infrastructure code using vagrant or test-kitchen many many times a day and it sucks having to download apt packages from mirrors that time out or get bogged down randomly. Previously I had used a test-kitchen plugin to deal with that which I’ll cover in another post. In this I’m going to go over some simple hacks I’ve managed to get working for speeding up building of docker images using docker for mac beta.\n\nSee this forum thread in regards to the ongoing headaches with networking in docker for mac beta. Link\n\nI was trying a bunch of ways to do this and just settled on the alias on lo0.\nI just added this to my bash alias.\n\n``` bash\nifconfig lo0 |grep 192.168.168.167 >/dev/null\nif [ $? -ne 0 ]; then\n  sudo ifconfig lo0 alias 192.168.168.167\nelse\n  echo \"docker host alias is in good shape move along.\"\nfi\n```\n\nMy use case was that I am running apt-cacher-ng on my mac natively. Using just a brew install apt-cacher-ng and running it as a service all the time. This speeds up test-kitchen and other configuration management tool testing.\n\nAdding this.\n\n``` bash\nARG APT_PROXY_PORT=\nARG HOST_IP=\nCOPY detect-apt-proxy.sh /root\nRUN /root/detect-apt-proxy.sh ${APT_PROXY_PORT}\n```\n\n\nThe contents of detect-apt-proxy.sh are as follows.\n\n``` bash\n#!/bin/bash\nset -x\nAPT_PROXY_PORT=$1\nif [ -z \"${HOST_IP}\" ]; then\n  HOST_IP=$(route -n | awk '/^0.0.0.0/ {print $2}')\nfi\nnc -z \"$HOST_IP\" ${APT_PROXY_PORT}\nif [ $? -eq 0 ]; then\n    cat >> /etc/apt/apt.conf.d/30proxy <<EOL\n    Acquire::http::Proxy \"http://$HOST_IP:$APT_PROXY_PORT\";\n    Acquire::http::Proxy::ppa.launchpad.net DIRECT;\nEOL\n    cat /etc/apt/apt.conf.d/30proxy\n    echo \"Using host's apt proxy\"\nelse\n    echo \"No apt proxy detected on Docker host\"\nfi\n```\n\nThen when building my docker images…\n\n``` bash \ndocker build -t newcontainer --build-arg APT_PROXY_PORT=3142 --build-arg HOST_IP=192.168.168.167 .\n```\n\nThis allows me to run the cacher locally and programmatically check for it inside the container and set the apt proxy options. This also works on Linux or docker-machine just leave off the build-arg for HOST_IP and it will use the older method of grabbing the gateway interface instead of the aliased interface…. This should in theory work with xhyve but the gateway interface is somehow hidden or locked down from the vm… Some insight on why you can’t access the gateway interface in xhyve vs virtualbox would be nice…","source":"_posts/apt-cacher-ng-with-docker-builds.md","raw":"---\ntitle: apt-cacher-ng with docker builds\ndate: 2016-07-20 14:05:46\ntags:\n    - DOCKER \n    - DOCKERFILE \n    - APT-CACHER-NG \n    - APT-GET \n    - UBUNTU \n    - CONFIGURATION \n    - DOCKER FOR MAC\n---\n\n# apt-cacher-ng with docker builds\n\nWorking with docker on a laptop testing configuration of containers has some of the same annoyances as working with other configuration managment tools and testing frameworks like test-kitchen, chef, ansible etc…\n\nIt takes forever to download dependencies. I might test some infrastructure code using vagrant or test-kitchen many many times a day and it sucks having to download apt packages from mirrors that time out or get bogged down randomly. Previously I had used a test-kitchen plugin to deal with that which I’ll cover in another post. In this I’m going to go over some simple hacks I’ve managed to get working for speeding up building of docker images using docker for mac beta.\n\nSee this forum thread in regards to the ongoing headaches with networking in docker for mac beta. Link\n\nI was trying a bunch of ways to do this and just settled on the alias on lo0.\nI just added this to my bash alias.\n\n``` bash\nifconfig lo0 |grep 192.168.168.167 >/dev/null\nif [ $? -ne 0 ]; then\n  sudo ifconfig lo0 alias 192.168.168.167\nelse\n  echo \"docker host alias is in good shape move along.\"\nfi\n```\n\nMy use case was that I am running apt-cacher-ng on my mac natively. Using just a brew install apt-cacher-ng and running it as a service all the time. This speeds up test-kitchen and other configuration management tool testing.\n\nAdding this.\n\n``` bash\nARG APT_PROXY_PORT=\nARG HOST_IP=\nCOPY detect-apt-proxy.sh /root\nRUN /root/detect-apt-proxy.sh ${APT_PROXY_PORT}\n```\n\n\nThe contents of detect-apt-proxy.sh are as follows.\n\n``` bash\n#!/bin/bash\nset -x\nAPT_PROXY_PORT=$1\nif [ -z \"${HOST_IP}\" ]; then\n  HOST_IP=$(route -n | awk '/^0.0.0.0/ {print $2}')\nfi\nnc -z \"$HOST_IP\" ${APT_PROXY_PORT}\nif [ $? -eq 0 ]; then\n    cat >> /etc/apt/apt.conf.d/30proxy <<EOL\n    Acquire::http::Proxy \"http://$HOST_IP:$APT_PROXY_PORT\";\n    Acquire::http::Proxy::ppa.launchpad.net DIRECT;\nEOL\n    cat /etc/apt/apt.conf.d/30proxy\n    echo \"Using host's apt proxy\"\nelse\n    echo \"No apt proxy detected on Docker host\"\nfi\n```\n\nThen when building my docker images…\n\n``` bash \ndocker build -t newcontainer --build-arg APT_PROXY_PORT=3142 --build-arg HOST_IP=192.168.168.167 .\n```\n\nThis allows me to run the cacher locally and programmatically check for it inside the container and set the apt proxy options. This also works on Linux or docker-machine just leave off the build-arg for HOST_IP and it will use the older method of grabbing the gateway interface instead of the aliased interface…. This should in theory work with xhyve but the gateway interface is somehow hidden or locked down from the vm… Some insight on why you can’t access the gateway interface in xhyve vs virtualbox would be nice…","slug":"apt-cacher-ng-with-docker-builds","published":1,"updated":"2016-08-02T21:10:43.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1budj0008hrtf4x8evx1j","content":"<h1 id=\"apt-cacher-ng-with-docker-builds\"><a href=\"#apt-cacher-ng-with-docker-builds\" class=\"headerlink\" title=\"apt-cacher-ng with docker builds\"></a>apt-cacher-ng with docker builds</h1><p>Working with docker on a laptop testing configuration of containers has some of the same annoyances as working with other configuration managment tools and testing frameworks like test-kitchen, chef, ansible etc…</p>\n<p>It takes forever to download dependencies. I might test some infrastructure code using vagrant or test-kitchen many many times a day and it sucks having to download apt packages from mirrors that time out or get bogged down randomly. Previously I had used a test-kitchen plugin to deal with that which I’ll cover in another post. In this I’m going to go over some simple hacks I’ve managed to get working for speeding up building of docker images using docker for mac beta.</p>\n<p>See this forum thread in regards to the ongoing headaches with networking in docker for mac beta. Link</p>\n<p>I was trying a bunch of ways to do this and just settled on the alias on lo0.<br>I just added this to my bash alias.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">ifconfig lo0 |grep 192.168.168.167 &gt;/dev/null</div><div class=\"line\"><span class=\"keyword\">if</span> [ $? <span class=\"_\">-ne</span> 0 ]; <span class=\"keyword\">then</span></div><div class=\"line\">  sudo ifconfig lo0 <span class=\"built_in\">alias</span> 192.168.168.167</div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">  <span class=\"built_in\">echo</span> <span class=\"string\">\"docker host alias is in good shape move along.\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<p>My use case was that I am running apt-cacher-ng on my mac natively. Using just a brew install apt-cacher-ng and running it as a service all the time. This speeds up test-kitchen and other configuration management tool testing.</p>\n<p>Adding this.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">ARG APT_PROXY_PORT=</div><div class=\"line\">ARG HOST_IP=</div><div class=\"line\">COPY detect-apt-proxy.sh /root</div><div class=\"line\">RUN /root/detect-apt-proxy.sh <span class=\"variable\">$&#123;APT_PROXY_PORT&#125;</span></div></pre></td></tr></table></figure>\n<p>The contents of detect-apt-proxy.sh are as follows.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\"><span class=\"built_in\">set</span> -x</div><div class=\"line\">APT_PROXY_PORT=<span class=\"variable\">$1</span></div><div class=\"line\"><span class=\"keyword\">if</span> [ -z <span class=\"string\">\"<span class=\"variable\">$&#123;HOST_IP&#125;</span>\"</span> ]; <span class=\"keyword\">then</span></div><div class=\"line\">  HOST_IP=$(route -n | awk <span class=\"string\">'/^0.0.0.0/ &#123;print $2&#125;'</span>)</div><div class=\"line\"><span class=\"keyword\">fi</span></div><div class=\"line\">nc -z <span class=\"string\">\"<span class=\"variable\">$HOST_IP</span>\"</span> <span class=\"variable\">$&#123;APT_PROXY_PORT&#125;</span></div><div class=\"line\"><span class=\"keyword\">if</span> [ $? <span class=\"_\">-eq</span> 0 ]; <span class=\"keyword\">then</span></div><div class=\"line\">    cat &gt;&gt; /etc/apt/apt.conf.d/30proxy &lt;&lt;EOL</div><div class=\"line\">    Acquire::http::Proxy <span class=\"string\">\"http://<span class=\"variable\">$HOST_IP</span>:<span class=\"variable\">$APT_PROXY_PORT</span>\"</span>;</div><div class=\"line\">    Acquire::http::Proxy::ppa.launchpad.net DIRECT;</div><div class=\"line\">EOL</div><div class=\"line\">    cat /etc/apt/apt.conf.d/30proxy</div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"Using host's apt proxy\"</span></div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"No apt proxy detected on Docker host\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<p>Then when building my docker images…</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker build -t newcontainer --build-arg APT_PROXY_PORT=3142 --build-arg HOST_IP=192.168.168.167 .</div></pre></td></tr></table></figure>\n<p>This allows me to run the cacher locally and programmatically check for it inside the container and set the apt proxy options. This also works on Linux or docker-machine just leave off the build-arg for HOST_IP and it will use the older method of grabbing the gateway interface instead of the aliased interface…. This should in theory work with xhyve but the gateway interface is somehow hidden or locked down from the vm… Some insight on why you can’t access the gateway interface in xhyve vs virtualbox would be nice…</p>\n","excerpt":"","more":"<h1 id=\"apt-cacher-ng-with-docker-builds\"><a href=\"#apt-cacher-ng-with-docker-builds\" class=\"headerlink\" title=\"apt-cacher-ng with docker builds\"></a>apt-cacher-ng with docker builds</h1><p>Working with docker on a laptop testing configuration of containers has some of the same annoyances as working with other configuration managment tools and testing frameworks like test-kitchen, chef, ansible etc…</p>\n<p>It takes forever to download dependencies. I might test some infrastructure code using vagrant or test-kitchen many many times a day and it sucks having to download apt packages from mirrors that time out or get bogged down randomly. Previously I had used a test-kitchen plugin to deal with that which I’ll cover in another post. In this I’m going to go over some simple hacks I’ve managed to get working for speeding up building of docker images using docker for mac beta.</p>\n<p>See this forum thread in regards to the ongoing headaches with networking in docker for mac beta. Link</p>\n<p>I was trying a bunch of ways to do this and just settled on the alias on lo0.<br>I just added this to my bash alias.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">ifconfig lo0 |grep 192.168.168.167 &gt;/dev/null</div><div class=\"line\"><span class=\"keyword\">if</span> [ $? <span class=\"_\">-ne</span> 0 ]; <span class=\"keyword\">then</span></div><div class=\"line\">  sudo ifconfig lo0 <span class=\"built_in\">alias</span> 192.168.168.167</div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">  <span class=\"built_in\">echo</span> <span class=\"string\">\"docker host alias is in good shape move along.\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<p>My use case was that I am running apt-cacher-ng on my mac natively. Using just a brew install apt-cacher-ng and running it as a service all the time. This speeds up test-kitchen and other configuration management tool testing.</p>\n<p>Adding this.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">ARG APT_PROXY_PORT=</div><div class=\"line\">ARG HOST_IP=</div><div class=\"line\">COPY detect-apt-proxy.sh /root</div><div class=\"line\">RUN /root/detect-apt-proxy.sh <span class=\"variable\">$&#123;APT_PROXY_PORT&#125;</span></div></pre></td></tr></table></figure>\n<p>The contents of detect-apt-proxy.sh are as follows.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#!/bin/bash</span></div><div class=\"line\"><span class=\"built_in\">set</span> -x</div><div class=\"line\">APT_PROXY_PORT=<span class=\"variable\">$1</span></div><div class=\"line\"><span class=\"keyword\">if</span> [ -z <span class=\"string\">\"<span class=\"variable\">$&#123;HOST_IP&#125;</span>\"</span> ]; <span class=\"keyword\">then</span></div><div class=\"line\">  HOST_IP=$(route -n | awk <span class=\"string\">'/^0.0.0.0/ &#123;print $2&#125;'</span>)</div><div class=\"line\"><span class=\"keyword\">fi</span></div><div class=\"line\">nc -z <span class=\"string\">\"<span class=\"variable\">$HOST_IP</span>\"</span> <span class=\"variable\">$&#123;APT_PROXY_PORT&#125;</span></div><div class=\"line\"><span class=\"keyword\">if</span> [ $? <span class=\"_\">-eq</span> 0 ]; <span class=\"keyword\">then</span></div><div class=\"line\">    cat &gt;&gt; /etc/apt/apt.conf.d/30proxy &lt;&lt;EOL</div><div class=\"line\">    Acquire::http::Proxy <span class=\"string\">\"http://<span class=\"variable\">$HOST_IP</span>:<span class=\"variable\">$APT_PROXY_PORT</span>\"</span>;</div><div class=\"line\">    Acquire::http::Proxy::ppa.launchpad.net DIRECT;</div><div class=\"line\">EOL</div><div class=\"line\">    cat /etc/apt/apt.conf.d/30proxy</div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"Using host's apt proxy\"</span></div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"No apt proxy detected on Docker host\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<p>Then when building my docker images…</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker build -t newcontainer --build-arg APT_PROXY_PORT=3142 --build-arg HOST_IP=192.168.168.167 .</div></pre></td></tr></table></figure>\n<p>This allows me to run the cacher locally and programmatically check for it inside the container and set the apt proxy options. This also works on Linux or docker-machine just leave off the build-arg for HOST_IP and it will use the older method of grabbing the gateway interface instead of the aliased interface…. This should in theory work with xhyve but the gateway interface is somehow hidden or locked down from the vm… Some insight on why you can’t access the gateway interface in xhyve vs virtualbox would be nice…</p>\n"},{"title":"smp affinity makes a difference","date":"2016-07-13T21:25:48.000Z","_content":"\n# A good driver.\n\nHaving a driver that uses the proper interrupt handling makes a difference in high bandwidth pci devices like RAID cards and Infiniband.\n\nFor example having the stock 2.6.32-220 megasas driver only makes use of one interrupt.\n\nThis was the stock driver in the centos 2.6.32-220 kernel\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n\n```\n\nThis is the driver from LSI compiled against the same kernel sources. Notice the additional interrupt usage.\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n\n```\n","source":"_posts/smp-affinity-makes-a-difference.md","raw":"---\ntitle: smp affinity makes a difference\ndate: 2016-07-13 14:25:48\ntags:\n---\n\n# A good driver.\n\nHaving a driver that uses the proper interrupt handling makes a difference in high bandwidth pci devices like RAID cards and Infiniband.\n\nFor example having the stock 2.6.32-220 megasas driver only makes use of one interrupt.\n\nThis was the stock driver in the centos 2.6.32-220 kernel\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n\n```\n\nThis is the driver from LSI compiled against the same kernel sources. Notice the additional interrupt usage.\n\n``` bash\n[root@demo mnt]# cat /proc/interrupts |grep megasas\n  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas\n\n```\n","slug":"smp-affinity-makes-a-difference","published":1,"updated":"2016-08-02T21:27:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cire1budl000bhrtfj6du42iy","content":"<h1 id=\"A-good-driver\"><a href=\"#A-good-driver\" class=\"headerlink\" title=\"A good driver.\"></a>A good driver.</h1><p>Having a driver that uses the proper interrupt handling makes a difference in high bandwidth pci devices like RAID cards and Infiniband.</p>\n<p>For example having the stock 2.6.32-220 megasas driver only makes use of one interrupt.</p>\n<p>This was the stock driver in the centos 2.6.32-220 kernel</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<p>This is the driver from LSI compiled against the same kernel sources. Notice the additional interrupt usage.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<h1 id=\"A-good-driver\"><a href=\"#A-good-driver\" class=\"headerlink\" title=\"A good driver.\"></a>A good driver.</h1><p>Having a driver that uses the proper interrupt handling makes a difference in high bandwidth pci devices like RAID cards and Infiniband.</p>\n<p>For example having the stock 2.6.32-220 megasas driver only makes use of one interrupt.</p>\n<p>This was the stock driver in the centos 2.6.32-220 kernel</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  79:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n<p>This is the driver from LSI compiled against the same kernel sources. Notice the additional interrupt usage.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@demo mnt]<span class=\"comment\"># cat /proc/interrupts |grep megasas</span></div><div class=\"line\">  80:       2506          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  81:        124          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  82:         24          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  83:          7          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  84:        993          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  85:         80          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  86:         17          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div><div class=\"line\">  87:          8          0          0          0          0          0          0          0  IR-PCI-MSI-edge      megasas</div></pre></td></tr></table></figure>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cire1bud30000hrtfjb4ftshd","tag_id":"cire1budb0002hrtfouxi1qe0","_id":"cire1budk000ahrtf47sqc2t6"},{"post_id":"cire1bud30000hrtfjb4ftshd","tag_id":"cire1budg0005hrtf0xq6gfae","_id":"cire1budm000chrtfycz0qq1m"},{"post_id":"cire1budg0006hrtfu97vgs5p","tag_id":"cire1budb0002hrtfouxi1qe0","_id":"cire1budo000ghrtf8q8hpj48"},{"post_id":"cire1budg0006hrtfu97vgs5p","tag_id":"cire1budk0009hrtfthquaslh","_id":"cire1budo000hhrtfyp36jr5b"},{"post_id":"cire1budg0006hrtfu97vgs5p","tag_id":"cire1budn000dhrtfhllqq19w","_id":"cire1budo000jhrtf3h85qjlg"},{"post_id":"cire1budg0006hrtfu97vgs5p","tag_id":"cire1budn000ehrtf9s1hjme5","_id":"cire1budo000khrtfcpoa0xpb"},{"post_id":"cire1budj0008hrtf4x8evx1j","tag_id":"cire1budn000fhrtfnw7wpl46","_id":"cire1budq000qhrtflwoo5bo4"},{"post_id":"cire1budj0008hrtf4x8evx1j","tag_id":"cire1budo000ihrtf1x29t0fq","_id":"cire1budq000rhrtfj3h12ngb"},{"post_id":"cire1budj0008hrtf4x8evx1j","tag_id":"cire1budo000lhrtf7pr336e1","_id":"cire1budq000shrtfr2d6y7xp"},{"post_id":"cire1budj0008hrtf4x8evx1j","tag_id":"cire1budp000mhrtfryw6mbd4","_id":"cire1budq000thrtftj5c43z0"},{"post_id":"cire1budj0008hrtf4x8evx1j","tag_id":"cire1budp000nhrtf5n87d7b9","_id":"cire1budq000uhrtfdzvtgoty"},{"post_id":"cire1budj0008hrtf4x8evx1j","tag_id":"cire1budp000ohrtfkp8gat78","_id":"cire1budq000vhrtfc1rfunqa"},{"post_id":"cire1budj0008hrtf4x8evx1j","tag_id":"cire1budp000phrtfoxl1c9m2","_id":"cire1budq000whrtf37c7c69y"}],"Tag":[{"name":"docker","_id":"cire1budb0002hrtfouxi1qe0"},{"name":"hacks","_id":"cire1budg0005hrtf0xq6gfae"},{"name":"golang","_id":"cire1budk0009hrtfthquaslh"},{"name":"go-dockerclient","_id":"cire1budn000dhrtfhllqq19w"},{"name":"go-dexec","_id":"cire1budn000ehrtf9s1hjme5"},{"name":"DOCKER","_id":"cire1budn000fhrtfnw7wpl46"},{"name":"DOCKERFILE","_id":"cire1budo000ihrtf1x29t0fq"},{"name":"APT-CACHER-NG","_id":"cire1budo000lhrtf7pr336e1"},{"name":"APT-GET","_id":"cire1budp000mhrtfryw6mbd4"},{"name":"UBUNTU","_id":"cire1budp000nhrtf5n87d7b9"},{"name":"CONFIGURATION","_id":"cire1budp000ohrtfkp8gat78"},{"name":"DOCKER FOR MAC","_id":"cire1budp000phrtfoxl1c9m2"}]}}